title,description,publishedAt,url,urlToImage,search_term,scraped_data
AI strikes again: Image of shirtless man kicking an alligator fools the internet,"As AI image generators become more advanced, it becomes increasingly difficult to tell AI from real images. So, it’s no wonder that yet another AI creation has been fooling people over the past few days. The image is downright bizarre, showing a half-naked ma…",03-10-23,https://www.diyphotography.net/ai-strikes-again-image-of-shirtless-man-kicking-an-alligator-fools-the-internet/,https://www.diyphotography.net/wp-content/uploads/2023/10/alligator-kick.jpg,AI,"




 




AI strikes again: Image of shirtless man kicking an alligator fools the internet





















































 

DIY PhotographyYour one stop shop for everything photo-videoNews
Inspiration
Reviews
Tutorials
DIY
Gear

 
Search









  











 




Leave this field empty if you're human: 


 Submit A Story

AI strikes again: Image of shirtless man kicking an alligator fools the internet
Oct 3, 2023 by Dunja Djudjic 3 Comments 

 


Share

 


Tweet

 


Flipboard

 


WhatsApp


As AI image generators become more advanced, it becomes increasingly difficult to tell AI from real images. So, it’s no wonder that yet another AI creation has been fooling people over the past few days. The image is downright bizarre, showing a half-naked man kicking an alligator in the face. It spread like wildfire, with some folks turning it into a meme and some wondering – is this thing real?

I saw the image on Instagram a day or two ago. A friend of mine shared it in a Story and joked that this is what his dreams have looked like lately. As Know Your Meme explains, this is an AI-generated image. It shows a “large, shirtless Black man kicking an alligator in the face in a swamp at night.”
According to the same source, it was first seen on the Facebook account Uncle Mike’s Photography. If you pay attention to the page’s username (in the URL), it’s www.facebook.com/ExtremeAiArt. Si the telltale sign whether this is real or not is already there. Not to mention the rest of the creations which are all surreal, and often hilarious or disturbing. Or both.






However, as it usually happens, someone took the image, shared it, and it started living a life of its own. According to Know Your Meme, it went viral on X / Twitter, shared both as a “story” of several images, and as a single image of the man kicking the alligator.

A story pic.twitter.com/gkNoWpkx3k— Fights n' Stuff (@FightsStuff) September 30, 2023


this is what tekken looks like pic.twitter.com/pliJ7TI8zg— 𝘣𝘰𝘰𝘵𝘭𝘦𝘨 𝘨𝘦𝘯𝘨𝘢𝘳 𝘱𝘭𝘶𝘴𝘩 (@twohealthbars) October 1, 2023

The problem is, if you see the kicking image out of context and out of Uncle Mike’s Photography’s page – it can be pretty hard to tell whether this is AI or not. At least if you disregard the pretty bizarre situation it depicts. People on Reddit have even wondered if the whole series of images was real.
“Is this AI or not?” one Redditor asked. “This is the first thing I’ve ever seen where I can’t tell if it’s AI or not and it’s really bugging me, help!”
One user pointed out to several telltale signs that reveal the truth about the images:

“The belly size seems inconsistent across the 3, the nipples and belly button don’t match across 2 and 3, there are no stretch marks in 3 like there are in 2, and the text on the side of the box is an indecipherable mess, in the first two the camo shorts has dark brown which is not in the 3rd picture, the beard is inconsistent as well if you look at the section right by the ear, no ripples at all near the guy when he is kicking and no water trailing off of his foot either
Where is the rest of the face of the croc to the left of the one being kicked? I initially thought it was just in shadow but that doesn’t line up with the lighting of everything else that seems strongly lit directly from the camera
I would say AI”

Another user added that the pizza box wasn’t soaking up water as you would expect. “And it has no lid,” added another.
Recognizing AI images
In this case, I simply used “AI or not” and it gave me the answer.

It’s all fun and games if we’re just making and exchanging memes. However, some AI images have confused people globally, and even caused serious problems. This is why it’s essential to think critically and double-check. When you see an image that causes a reaction and leaves a strong impression, take a moment. Don’t react or share it immediately. Take a second look instead, and if your guts tell you something’s not right, it probably isn’t, so go ahead and do your check!
 [via PetaPixel]
FIND THIS INTERESTING? SHARE IT WITH YOUR FRIENDS!

 


Share

 


Tweet

 


Flipboard

 


WhatsApp
 
 





Related posts:


The Streisand Effect strikes again!  “Unflattering” photograph Peter Dutton wants removed from the Internet goes viral

Shirtless selfie spawns nude houseplant photo trolling in Facebook hobbyist group

Watch: Alligator turns into smoke-billowing dragon after chomping down on drone

Huge alligator filmed in Florida sewer system with robotic camera



Filed Under: news About Dunja DjudjicDunja Djudjic is a multi-talented artist based in Novi Sad, Serbia. With 15 years of experience as a photographer, she specializes in capturing the beauty of nature, travel, and fine art. In addition to her photography, Dunja also expresses her creativity through writing, embroidery, and jewelry making.
« Apple says it will fix iPhone 15 Pro overheating problemsDog ‘driving’ a speeding car caught by traffic camera »

 















Leave this field empty if you're human: 
Submit A Story
Get our FREE Lighting Book












 Daily


 Weekly



* download requires newsletter signup
Leave this field empty if you're human: 
Recent Comments


 
Which social media do you use for sharing photos

Free Resources
Advanced lighting book

Learn photography



Recent Posts


NASA’s Perseverance rover captures video of 1.2 miles tall dust devil on Mars


This is what happened after a roll of film was X-rayed 19 times


This map is your ultimate guide to the 2023 and 2024 solar eclipses


Dog ‘driving’ a speeding car caught by traffic camera


AI strikes again: Image of shirtless man kicking an alligator fools the internet



Udi Tirosh is an entrepreneur, photography inventor, journalist, educator, and writer based in Israel. With over 25 years of experience in the photo-video industry, Udi has built and sold several photography-related brands. Udi has a double degree in mass media communications and computer science.

Alex Baker is a portrait and lifestyle driven photographer based in Valencia, Spain. She works on a range of projects from commercial to fine art and has had work featured in publications such as The Daily Mail, Conde Nast Traveller and El Mundo, and has exhibited work across Europe

Dave Williams is an accomplished travel photographer, writer, and best-selling author from the UK. He is also a photography educator and published Aurora expert. Dave has traveled extensively in recent years, capturing stunning images from around the world in a modified van. His work has been featured in various publications and he has worked with notable brands such as Skoda, EE, Boeing, Huawei, Microsoft, BMW, Conde Nast, Electronic Arts, Discovery, BBC, The Guardian, ESPN, NBC, and many others.

John Aldred is a photographer with over 20 years of experience in the portrait and commercial worlds. He is based in Scotland and has been an early adopter - and occasional beta tester - of almost every digital imaging technology in that time. As well as his creative visual work, John uses 3D printing, electronics and programming to create his own photography and filmmaking tools and consults for a number of brands across the industry.

Dunja Djudjic is a multi-talented artist based in Novi Sad, Serbia. With 15 years of experience as a photographer, she specializes in capturing the beauty of nature, travel, and fine art. In addition to her photography, Dunja also expresses her creativity through writing, embroidery, and jewelry making.

Copyright © DIYPhotography 2006 - 2023 | About | Contact | Advertise | Write for DIYP | Full Disclosure | Privacy Policy




















"
Tom Hanks warns of dental ad with an AI clone,SAN FRANCISCO - Actor Tom Hanks and CBS talk show co-host Gayle King on Monday were warning fans about ads featuring impostors generated by artificial intelligence (AI).,03-10-23,https://www.bangkokpost.com/life/tech/2656782/american-actor-tom-hanks-warns-of-dental-advertisement-with-an-artificial-intelligence-clone,https://static.bangkokpost.com/media/content/20231003/c1_2656782_700.jpg, ChatGPT,"






Tom Hanks warns of dental ad with an AI clone




































































































































NEWS

THAILAND
BUSINESS
OPINION
WORLD
PROPERTY
SPORTS



THAILAND

GENERAL
POLITICS
SPECIAL REPORT
PR NEWS



BUSINESS

GENERAL
MOTORING
INVESTMENT



LIFE

ARTS &
										ENTERTAINMENT
SOCIAL &
										LIFESTYLE
TRAVEL
TECH



GURU

EAT
TRAVEL
JOIN
WATCH
STUFF
HOROSCOPE
DEALS


LEARNING

MULTIMEDIA

VIDEO
PHOTOS
PODCAST






























SUBSCRIBE






NEWS
NEWS


ALL NEWS


THAILAND

- General

-
															Politics
- Special report
- PR news



BUSINESS

- General

-
															Motoring
-
															Investment




OPINION

- Columnist

- Postbag




WORLD


PROPERTY


SPORTS






LIFE
LIFE


ALL LIFE


ARTS & ENTERTAINMENT


SOCIAL & LIFESTYLE


TRAVEL


TECH




LEARNING


GURU
GURU


ALL GURU


EAT


TRAVEL


JOIN


WATCH


STUFF


HOROSCOPE


DEALS






VIDEO
VIDEO


ALL VIDEO


THAILAND



WORLD


TRAVEL & LIFESTYLE


BUSINESS





PHOTOS


PODCAST


EVENTS


SPECIAL FEATURES






SERVICES
SERVICES


SUBSCRIPTION


JOB


E-NEWSLETTER


SMS




OTHER
OTHER


CONTACT US


TELL US WHAT
														YOU THINK


























 Tom Hanks warns of dental ad with an AI clone























Life
Tech



Tom Hanks warns of dental ad with an AI clone
Google, Meta and Microsoft are among those racing to capitalise on the promise of generative AI 
TECH



PUBLISHED : 3 Oct 2023 at 15:44

WRITER: 
															South China Morning Post



























SAN FRANCISCO - Actor Tom Hanks and CBS talk show co-host Gayle King on Monday were warning fans about ads featuring impostors generated by artificial intelligence (AI). ""Beware,"" Hanks said in an Instagram post that evidently showed a copy of an unauthorised digital version of him.
""There is a video out there promoting some dental plan with an AI version of me. I have nothing to do with it.""
The message had received more than 111,700 ""likes"" since the Academy Award winning actor posted it to his 9.5 million followers on Instagram on Sunday.
King, a co-host of CBS Mornings talk show, posted what she said was a bogus video clip of her enticing viewers to click on a link to learn about her weight loss ""secret"".
""I have nothing to do with this company,"" King said in her Instagram post.
Disney use of AI for Marvel's Secret Invasion series spooks Hollywood
""I've never heard of this product or used it! Please don't be fooled by these AI videos.""

Actor Tom Hanks speaks during a media preview ahead of the opening of the Academy Museum of Motion Pictures in Los Angeles, California, on Sept 21, 2021. (Photo: Reuters)

Safeguards against AI being used to replicate screen talent was among the issues fought over during a writers strike that paralysed Hollywood until a recent tentative deal.
The still ongoing strike by Hollywood actors has yet to be resolved.
Generative AI programs burst into the spotlight late last year, with ChatGPT demonstrating an ability to generate essays, poems and conversations from the briefest prompts.
AI models have added capabilities such as being able to generate digital imagery on command, raising fears the technology will be used to create ""deep fake"" pictures and videos that fool people into thinking they real.
Tech titans Google, Meta and Microsoft are among those racing to capitalise on the promise of generative AI while trying to avoid perils such as the technology's potential as a weapon for misinformation and cybercrime. 



KEYWORDS

														artificial intelligence

														tom hanks

														advertisement

														hollywood



								Do you like the content of this article?
								 


 COMMENT
																			
















RECOMMENDED






Capturing the many faces of khon
Life





Your horoscope for Sept 29 - Oct 5
Life





Old places, new menus
Life





Blend of luxury and nature
Life





Blending Asian heritage and Parisian elegance
Life









TRENDING































NEWS


THAILAND

- General
- Politics
- Special report
- PR news



BUSINESS

- General
- Motoring
- Investment




OPINION

- Columnist
- Postbag



WORLD


PROPERTY


SPORTS






LIFE


ARTS & ENTERTAINMENT


SOCIAL & LIFESTYLE


TRAVEL


TECH




LEARNING


GURU


EAT


TRAVEL


JOIN


WATCH


STUFF


HOROSCOPE


DEALS






VIDEO


THAILAND



WORLD


TRAVEL & LIFESTYLE


BUSINESS






PHOTOS


PODCAST


EVENTS


SPECIAL FEATURES







DIGITAL PRODUCTS & SERVICES


E-PAPER


SMS


JOBS


HOME DELIVERY






OTHER


CONTACT US


TELL US WHAT
														YOU THINK






STAY INFORMED.GET DAILY UPDATES FROMTHE BANGKOK POST.



Please put in a valid-email.
SUBSCRIBE


By subscribing, you accept the terms and conditions in our privacy policy.








© 2023 Bangkok Post Public Company Limited

Terms of use
Republishing permission
Privacy policy
Cookies policy
Online advertising
Contact us
Tell us what you think
Partnership







 



















"
"Nigeria’s Ambitious Plan: Creating 50,000 Jobs through AI by 2030","To facilitate significant technological and economic advancements, the Nigerian Federal Government has set a remarkable target of producing approximately 50,000 job opportunities through Artificial Intelligence (AI) by 2030. This audacious ambition was disclo…",03-10-23,https://www.cryptopolitan.com/nigerias-ambitious-plan-creating-50000-jobs/,https://img.cryptopolitan.com/wp-content/uploads/2023/10/photo_5828010603808144372_y.jpg, Artificial Intelligence,"  Nigeria’s Ambitious Plan: Creating 50,000 Jobs through AI by 2030 – Cryptopolitan           
Skip to content



















































Converter 

NewsBitcoinBinanceRippleEthereumCardanoDogecoinDeFiNFTETFsPrice PredictionsBitcoinEthereumCardanoXRPDogecoinLitecoinBitcoin CashChainlinkEthereum ClassicVeChainTronEOSCROAlgorandZcashHolochainZilliqaDigibyteDentKINMATICWRXSHIBUNIDOTBNBSUSHIAAVECAKEENJWINKSolanaPIVXVoyagerAvalancheDentacoinArdorLCXVIBETRACSTEEMXYOBAXTRBCROREQLoopringDecentralandCosmosLearnCrypto 101Crypto WalletsCrypto InvestingCrypto MiningRegulationResearchScamsTechnologyBlockchain GamingMetaverseStoriesWeb3 Masterminds



































NewsBitcoinBinanceRippleEthereumCardanoDogecoinDeFiNFTETFsPrice PredictionsBitcoinEthereumCardanoXRPDogecoinLitecoinBitcoin CashChainlinkEthereum ClassicVeChainTronEOSCROAlgorandZcashHolochainZilliqaDigibyteDentKINMATICWRXSHIBUNIDOTBNBSUSHIAAVECAKEENJWINKSolanaPIVXVoyagerAvalancheDentacoinArdorLCXVIBETRACSTEEMXYOBAXTRBCROREQLoopringDecentralandCosmosLearnCrypto 101Crypto WalletsCrypto InvestingCrypto MiningRegulationResearchScamsTechnologyBlockchain GamingMetaverseStoriesWeb3 MastermindsFollow us











Search for:


Home » AI
Nigeria’s Ambitious Plan: Creating 50,000 Jobs through AI by 2030
October 3, 2023 by Brenda Kanana
2 mins read
  
Content 
1.
Five pillars: the strategy’s underpinnings
 
2.
Challenges and adaptation
 
3.
A vision for Nigeria’s AI future
TLDRNigeria’s government plans to create 50,000 jobs with AI by 2030, aiming to boost economic growth.They’ve laid out a blueprint with five key pillars: knowledge, policy, infrastructure, innovation, and trade.The government encourages global collaboration and research to make Nigeria a leader in AI, foreseeing significant economic benefits.To facilitate significant technological and economic advancements, the Nigerian Federal Government has set a remarkable target of producing approximately 50,000 job opportunities through Artificial Intelligence (AI) by 2030. This audacious ambition was disclosed by Dr. Bosun Tijani, the Minister of Communications, Innovation, and Digital Economy, as he introduced the ministry’s extensive strategy for the upcoming four years.This visionary plan, which spans 31 pages under the title ‘Accelerating Our Collective Prosperity Through Technical Efficiency,’ draws inspiration from influential reports authored by PwC, McKinsey Global Institute, and Accenture. Dr. Tijani maintains that AI is set to inaugurate a new era characterized by technological and economic metamorphosis within the next two decades.Acknowledging the pressing need for Nigeria, as an emerging economy, to prudently and inclusively harness AI’s potential, Minister Tijani underscores the necessity for an extensive national strategy. This strategy is designed to enhance Nigeria’s standing as a top global hub for AI model training and talent and to assert the nation’s leadership in promoting inclusiveness in AI datasets on a worldwide scale.The comprehensive plan articulates precise objectives. Nigeria aspires to enhance its global ranking in AI preparedness and adoption, gauged across several pivotal metrics, including computational capabilities, proficiency, data accessibility, ethics, and governance. The ultimate aim is to attain a top-50 ranking by the year 2030.Five pillars: the strategy’s underpinningsThe blueprint revolves around five crucial pillars, each being an indispensable component of the ministry’s mission and interlinked with the others:  Knowledge: Knowledge is the foundation of innovation, underpinned by sound policies.Policy: Sound policies provide the requisite framework for developing AI in Nigeria. Infrastructure: A robust digital infrastructure is an essential backbone for a thriving digital economy. Innovation and Entrepreneurship: These facets drive economic diversification, fostering innovation and job creation.Trade: Nigeria is steadfast in its commitment to global collaboration and partnerships, recognizing that innovation transcends geographical boundaries.Challenges and adaptationMinister Tijani concedes that the path ahead may present obstacles but emphasizes that it is through overcoming these challenges that progress is made. The government remains steadfast in its sense of purpose. It aims to harness the potency of technology to elevate Nigeria’s global standing, establish sustainable employment opportunities, and enhance the quality of life for all Nigerians.In August, Minister Tijani issued a call for applications from researchers of Nigerian descent across the globe to contribute to the formulation of Nigeria’s National AI Strategy. This call to action is grounded in a PwC report, which forecasts that AI could inject up to $15.7 trillion into the global economy by 2030. Of this total, $3 trillion is expected to result from heightened productivity, while $9.1 trillion would be derived from novel products and services.A vision for Nigeria’s AI futureThe Nigerian Federal Government has unveiled an ambitious vision for the future: AI plays a pivotal role in propelling economic growth, job creation, and global competitiveness. Nigeria is positioning itself as a global leader in this arena with a well-defined strategy and a commitment to harnessing AI responsibly and inclusively. While challenges may surface, as Minister Tijani reiterates, it is through surmounting these challenges that Nigeria will evolve and adapt, fully harnessing the potential of technology for the betterment of all its citizens.Disclaimer. The information provided is not trading advice. Cryptopolitan.com holds no liability for any investments made based on the information provided on this page. We strongly recommend independent research and/or consultation with a qualified professional before making any investment decisions.Share link:




























Written by Brenda Kanana  
Categories AI, Trending News Tags AI in Nigeria, Nigerian Federal GovernmentAssassin’s Creed Mirage Release Date, Pre-Load Details, and Editions RevealedJapan Startup Develops ‘Gundam’-Like Robot with $3-Million Price TagMost readBitcoin Price Prediction 2023-2032: Will Bitcoin Bulls Rally?How Can You Rate Plasma vs Sidechains Based on Features and Applications?Dogelon Mars Price Prediction 2023-2032: Is ELON a Good Investment?A Decade of Spotting Fraud, Fighting Scams, and a Fitting Closer – The SBF/FTX CatastropheJordan Financial Expo & Award, where the past embraces the blockchain-based future  Related News
Show All




How AI Is Teaching Old Banners New Tricks: Enhancing Efficiency and Creativity in Digital Advertising            	
October 4, 20233 mins read




SoftBank CEO Masayoshi Sets Timeline for Artificial General Intelligence Revolution            	
October 4, 20232 mins read




Meta’s Reality Labs Division Plans Layoffs in Silicon Unit            	
October 4, 20233 mins read




Tech Industry Sees Layoffs in 2023 Amidst Ongoing Transformation            	
October 4, 20233 mins read













Cryptopolitan dailyDiscover our daily newsletter, empowering investors with market insights.
Subscribe



















Your gateaway into the world of Web3Top SectionNewsPrice predictionBitcoin newsRegulationResearchScamsTechnologyLearnAIGamingCompanyAboutContactEventsStoriesWrite for usApply for ...Advertise with usOur ProductsCurrency ConverterCrypto portoflio tracker
Social Block cme



















Your gateaway into the world of Web3
Copyright 2023 CryptopolitanPrivacy PolicyEditorial PolicyCookie PolicyComment PolicyTerms and conditionsCryptopolitan                             

"
UOB first Singapore bank to trial Microsoft's AI-powered productivity tool,UOB first Singapore bank to trial Microsoft's AI-powered productivity tool,03-10-23,https://www.investing.com/news/stock-market-news/uob-first-singapore-bank-to-trial-microsofts-aipowered-productivity-tool-93CH-3188790,https://i-invdn-com.investing.com/news/LYNXNPEC4G11Q_L.jpg, Microsoft Copilot,
"There's big risk in not knowing what OpenAI is building in the cloud, warn Oxford scholars","The language-model-as-a-service industry is concealing critical details about reliability and trustworthiness, warns a report by the University of Oxford and its collaborators.",03-10-23,https://www.zdnet.com/article/theres-big-risk-in-not-knowing-what-openai-is-building-in-the-cloud-warn-oxford-scholars/,https://www.zdnet.com/a/img/resize/459e31f9d5c1cfe4bd359bb4da368d544432e045/2023/10/02/ab4c507c-4da3-4863-bcd5-7ed909291ccd/gettyimages-1398656750.jpg?auto=webp&fit=crop&height=675&width=1200,OpenAI,"


There's big risk in not knowing what OpenAI is building in the cloud, warn Oxford scholars | ZDNET


                                         />                                                                                                                                                                                                   X     Trending    New iPhone 15 models compared: iPhone 15 vs. Plus vs. Pro vs. Pro Max What is ChatGPT and why does it matter? Is Temu legit? What to know about this shopping app before you place an order Special Feature: The Rise of Generative AI ZDNET Recommends This tiny PC is a big deal: Plenty of ports and power for a very low price  The best earbuds you can buy The best live TV streaming services Buying an Apple Watch? Here's how to pick the best one for you Mesh routers vs. Wi-Fi routers: What's best for your home office? Best smartphones  Best laptops Best VPNs Best TVs Best headphones Best robot vacuums  Tech    Gaming Headphones Laptops Mobile Accessories Networking PCs  Printers Smartphones Smart Watches Speakers Streaming Devices Streaming Services  Tablets TVs Wearables  Kitchen & Household Office Furniture Office Hardware & Appliances Smart Home Smart Lighting Yard & Outdoors  Innovation    Artificial Intelligence AR + VR Cloud Digital Transformation Energy  Robotics Sustainability Transportation Work Life  Accelerate your tech game Paid Content How the New Space Race Will Drive Innovation How the metaverse will change the future of work and society  Managing the Multicloud The Future of the Internet The New Rules of Work The Tech Trends to Watch in 2023  Business    See all Business Amazon Apple Developer E-Commerce  Edge Computing Enterprise Software Executive Google Microsoft  Professional Development Social Media SMB Windows  Digital transformation: Trends and insights for success Software development: Emerging trends and changing roles  Security      See all Security Cyber Threats Password Manager Ransomware VPN  Cybersecurity: Let's get tactical Securing the Cloud  Advice      Deals How-to Product Comparisons Product Spotlights Reviews  Buying Guides    See all Buying Guides Best all-in-one computers Best budget TVs Best gaming CPUs Best gaming laptops Best gaming PCs  Best headphones Best iPads Best iPhones Best laptops Best large tablets Best OLED TVs  Best robot vacuum mops Best rugged tablets Best Samsung phones Best smart rings Best smartphones Best smartwatches  Best speakers Best tablets Best travel VPNs Best TVs Best VPNs   tomorrow belongs to those who embrace it today       
          Asia
        
          Australia
        
          Europe
        
          India
        
          United Kingdom
        
          United States
         ZDNET France ZDNET Germany ZDNET Korea ZDNET Japan        Go  Most Popular          See all Topics Finance Education Health  Special Features ZDNET In Depth ZDNET Recommends  Newsletters Videos Editorial Guidelines        Trending  New iPhone 15 models compared: iPhone 15 vs. Plus vs. Pro vs. Pro Max What is ChatGPT and why does it matter? Is Temu legit? What to know about this shopping app before you place an order Special Feature: The Rise of Generative AI ZDNET Recommends This tiny PC is a big deal: Plenty of ports and power for a very low price The best earbuds you can buy The best live TV streaming services Buying an Apple Watch? Here's how to pick the best one for you Mesh routers vs. Wi-Fi routers: What's best for your home office? Best smartphones Best laptops Best VPNs Best TVs Best headphones Best robot vacuums Tech  Gaming Headphones Laptops Mobile Accessories Networking PCs Printers Smartphones Smart Watches Speakers Streaming Devices Streaming Services Tablets TVs Wearables Kitchen & Household Office Furniture Office Hardware & Appliances Smart Home Smart Lighting Yard & Outdoors Innovation  Artificial Intelligence AR + VR Cloud Digital Transformation Energy Robotics Sustainability Transportation Work Life Accelerate your tech game Paid Content How the New Space Race Will Drive Innovation How the metaverse will change the future of work and society Managing the Multicloud The Future of the Internet The New Rules of Work The Tech Trends to Watch in 2023 Business  See all Business Amazon Apple Developer E-Commerce Edge Computing Enterprise Software Executive Google Microsoft Professional Development Social Media SMB Windows Digital transformation: Trends and insights for success Software development: Emerging trends and changing roles Security  See all Security Cyber Threats Password Manager Ransomware VPN Cybersecurity: Let's get tactical Securing the Cloud Advice  Deals How-to Product Comparisons Product Spotlights Reviews Buying Guides  See all Buying Guides Best all-in-one computers Best budget TVs Best gaming CPUs Best gaming laptops Best gaming PCs Best headphones Best iPads Best iPhones Best laptops Best large tablets Best OLED TVs Best robot vacuum mops Best rugged tablets Best Samsung phones Best smart rings Best smartphones Best smartwatches Best speakers Best tablets Best travel VPNs Best TVs Best VPNs More  See all Topics Finance Education Health Special Features ZDNET In Depth ZDNET Recommends Newsletters Videos Editorial Guidelines  Innovation     
      Home
    
      Innovation
    
      Artificial Intelligence
      
    There's big risk in not knowing what OpenAI is building in the cloud, warn Oxford scholars
   
    The language-model-as-a-service industry is concealing critical details about reliability and trustworthiness, warns a report by the University of Oxford and its collaborators.
      Written by 
            Tiernan Ray, Senior Contributing Writer   
        on
        Oct. 3, 2023                      OsakaWayne Studios/Getty ImagesOne of the seminal events in artificial intelligence (AI) in 2023 was the decision by OpenAI, the creator of ChatGPT, to disclose almost no information about its latest large language model (LLM), GPT-4, when the company introduced the program in March. That sudden swing to secrecy is becoming a major ethical issue for the tech industry because no one knows, outside OpenAI and its partner Microsoft, what is going on in the black box in their computing cloud. Also: With GPT-4, OpenAI opts for secrecy versus disclosureThe obfuscation is the subject of a report this month by scholars Emanuele La Malfa at the University of Oxford and collaborators at The Alan Turing Institute and the University of Leeds. In a paper posted on the arXiv pre-print server, La Malfa and colleagues explore the phenomenon of ""Language-Models-as-a-Service"" (LMaaS), referring to LLMs that are hosted online, either behind a user interface, or via an API. The primary examples of that approach are OpenAI's ChatGPT and GPT-4. ""Commercial pressure has led to the development of large, high-performance LMs [language models], accessible exclusively as a service for customers, that return strings or tokens in response to a user's textual input -- but for which information on architecture, implementation, training procedure, or training data is not available, nor is the ability to inspect or modify its internal states offered,"" write the authors.    Differences between open-source language models and LMaaS. A user of open-source programs has complete control, while customers of an LMaaS service have to make do with what they get though a browser or an API.  University of OxfordThose access restrictions ""inherent to LMaaS, combined with their black-box nature, are at odds with the need of the public and the research community to understand, trust, and control them better,"" they observe. ""This causes a significant problem at the field's core: the most potent and risky models are also the most difficult to analyze.""The problem is one that has been pointed out by many parties, including competitors to OpenAI, especially those banking on open-source code to beat out closed-source code. For example, Emad Mostaque, CEO of generative AI startup Stability.ai, which produces tools such as the image generator Stable Diffusion, has said that no enterprises can trust closed-source programs such as GPT-4. ""Open models will be essential for private data,"" said Mostaque during a small meeting of press and executives in May. ""You need to know everything that's inside it; these models are so powerful."" Also: GPT-3.5 vs GPT-4: Is ChatGPT Plus worth its subscription fee?La Malfa and team review the literature of the various language models, and identify how obfuscation prevents an audit of the programs along four critical factors: accessibility, replicability, comparability, and trustworthiness. The authors note that these concerns are a new development in AI ethics: ""These issues are specific to the LMaaS paradigm and distinct from preexisting concerns related to language models.""Also: Why open source is essential to allaying AI fears, according to Stability.ai founderAccessibility concerns the issue of keeping code secret, which disproportionately benefits huge companies with huge R&D budgets, the writers allege. ""With the computational power distributed unevenly and concentrated in a tiny number of companies,"" they write, ""those with a technological, yet not computational, advantage face a dilemma: While open-sourcing their LMaaS would benefit them in terms of market exposure and contribution to their codebase by the community, releasing the code that powers a model may rapidly burn their competitive advantage in favour of players with higher computational resources.""In addition, the uniform pricing of the LMaaS programs means people in less developed economies are at a disadvantage in accessing the tools. ""A starting point to mitigate these issues is thus analyzing the impact of LMaaS and, more generally, pay-per-usage artificial intelligence services as a standalone, pervasive, and disruptive technology,"" they suggest.Another issue is the increasing gap in how LLMs are trained: the commercial ones can re-use customer prompts and thereby set themselves apart from programs that use only public data, the authors observe. Also: How does ChatGPT work?LMaaS' commercial licenses, they write, ""grant companies the right to use prompts to provide, maintain, and improve their services,"" so that there's no common baseline of training data from which everyone draws. They offer a chart (below) that assesses the disparity in whether language models gather customer prompts for training and ""fine-tuning"", which is a stage that in some cases enhances a language model's abilities, and whether they let users opt out.    Comparison of whether language models offer opt-outs to their customers with respect to data, and whether they use the data for training and fine-tuning their black-box models.  University of OxfordAfter describing at length the various risks, La Malfa and team propose ""a tentative agenda"" to address the four areas, urging, ""we need to work as a community to find solutions that enable researchers, policymakers, and members of the public to trust LMaaS.""For one, they recommend that ""companies should release the source code"" of their LMaaS programs, if not to the general public, then ""LMaaS should at least be available to auditors/evaluators/red teams with restrictions on sharing.""Also: AI bots have been acing medical school exams, but should they become your doctor?Companies, they propose, should not totally do away with older language models as they roll out new ones. Or, at least, ""all the parameters that make up a model should be hashed, and a log of 'model commits' should be offered by model maintainers to the user, as the maintainer updates the model."" And the field, including journals and conferences, should ""discourage the usage of models"" that don't pursue such precautions. For benchmarking, tools need to be developed to test what elements an LMaaS has digested of its prompts, so that the baseline can be set accurately.  Clearly, with LMaaS, the topic of AI ethics has entered a new phase, one in which critical information is kept under lock and key, making ethical choices a more difficult matter for everyone than they have been in past. Artificial Intelligence    

          Generative AI will far surpass what ChatGPT can do. Here's everything on how the tech advances
         

          ChatGPT's new web browsing feature is a big disappointment. Use this plugin instead
         

          What is Amazon Bedrock? 4 ways it can help businesses use generative AI tools
         

          Can generative AI solve computer science's greatest unsolved problem?
            

            Generative AI will far surpass what ChatGPT can do. Here's everything on how the tech advances
           

            ChatGPT's new web browsing feature is a big disappointment. Use this plugin instead
           

            What is Amazon Bedrock? 4 ways it can help businesses use generative AI tools
           

            Can generative AI solve computer science's greatest unsolved problem?
           Editorial standards  Show Comments  
          Log In to Comment
         Community Guidelines     Related   
      What is artificial general intelligence really about? Conquering the last leg of the AI arms race
      
      Is AI in software engineering reaching an 'Oppenheimer moment'? Here's what you need to know
      
      Nearly 10% of people ask AI chatbots for explicit content. Will it lead LLMs astray?
              ZDNET we equip you to harness the power of disruptive innovation, at work and at home. TopicsGalleriesVideosDo Not Sell or Share My Personal Information about ZDNETMeet The TeamSitemapReprint Policy Join |
    Log InNewslettersSite AssistanceLicensing     
  © 2023 ZDNET, A Red Ventures company. All rights reserved.
 Privacy Policy |
  Cookie Settings |
  Advertise |
  Terms of Use 


"
What the WGA’s Historic Contract Means for All Writers in the Fight Against Generative AI,"The funniest picket sign I saw during the Writers Guild of America’s 148-day long strike came on Pretty Little Liars day, way back in mid-June. It was in the hands of actress Troian Bellisario and it read: “AI would have had me calling the cops… Season One.” …",03-10-23,https://lithub.com/what-the-wgas-historic-contract-means-for-all-writers-in-the-fight-against-generative-ai/,https://s26162.pcdn.co/wp-content/uploads/2023/09/wga-strike.jpg,OpenAI,"



What the WGA’s Historic Contract Means for All Writers in the Fight Against Generative AI ‹ Literary  Hub

































































































































Craft and Criticism
Fiction and Poetry
News and Culture
Lit Hub Radio
Reading Lists
Book Marks
CrimeReads
About
 




























								Literary Hub
							













Craft and Criticism Literary Criticism
Craft and Advice
In Conversation
On Translation

Fiction and Poetry Short Story
From the Novel
Poem

News and Culture The Virtual Book Channel
Film and TV
Music
Art and Photography
Food
Travel
Style
Design
Science
Technology
History
Biography
Memoir
Bookstores and Libraries
Freeman’s
Sports
The Hub

Lit Hub Radio Behind the Mic
Beyond the Page
The Cosmic Library
Emergence Magazine
Fiction/Non/Fiction
First Draft: A Dialogue on Writing
Just the Right Book
Keen On
Literary Disco
The Literary Life with Mitchell Kaplan
The Maris Review
New Books Network
Open Form
Otherppl with Brad Listi
So Many Damn Books
Thresholds
Tor Presents: Voyage Into Genre
Windham-Campbell Prizes Podcast
WMFA

Reading Lists The Best of the Decade

Book Marks Best Reviewed Books
BookMarks Daily Giveaway

CrimeReads True Crime
The Daily Thrill
CrimeReads Daily Giveaway

 


























					What the WGA’s Historic Contract Means for All Writers in the Fight Against Generative AI					
Alexis Gunderson on the Wins of Hollywood’s Hot Labor Summer


By Alexis Gunderson

October 3, 2023










The funniest picket sign I saw during the Writers Guild of America’s 148-day long strike came on Pretty Little Liars day, way back in mid-June. It was in the hands of actress Troian Bellisario and it read: “AI would have had me calling the cops… Season One.”
If you watched even a fraction of the show that made a clue-whistling parrot famous, you’ll get the joke immediately. Never mind how long it took Bellisario’s Spencer to call a single cop—this is a show that wrote a threat on a miniature scroll of parchment and stuffed it between an unconscious teen girl’s molars, sewed finger bones into the corset of a fashion show bridal gown, and turned (as a jape in the eleventh hour!) a whole side character into a cremation diamond. I don’t care how advanced generative AI technology might eventually get: you will never convince me that anything less than a room of deeply weird, deeply flawed human brains could come up with a show even half as gloriously unhinged.
Stiil, apt as I found Belisario’s sign to be, the sanctity of human creativity wasn’t the main reason generative AI haunted the WGA picket lines all summer. As the studios’ dismissive out-of-hand rejection to the Guild’s initial set of contract proposals so sharply underscored, the specter of generative AI was on the picket lines for the same reason the writers were: the future and respect of the profession itself.
To that point, and to be crystal clear about the stakes in play here, this is what the WGA asked for during the original round of contract negotiation back in May: “Regulate use of artificial intelligence on MBA-covered projects: AI can’t write or rewrite literary material; can’t be used as source material; and MBA-covered material can’t be used to train AI.”
The studios rejected the proposal and “countered by offering annual meetings to discuss advancements in technology.”
Please note that less than two months after this laughable counter-proposal was made, GPT-4 was made available to the general public. A little over a month later, Gizmodo had fired its Gizmodo en Español staff and put an AI translator on their beat. Within more or less the same news cycle as the WGA’s memorandum of agreement was released, OpenAI pushed a splashy announcement that “ChatGPT can now see, hear, and speak.” And the studios were out here offering annual meetings! To simply discuss advancements in technology! Absolutely wild.
Wild and, perhaps unsurprisingly, galvanizing.
“[The studios’] response really did change the conversation,” Mr. Robot writer Ted Kupper said in a phone interview earlier this summer. “I think if they had come back with a reasonable compromise, that would have been one thing. Instead they were like, well, we’ll promise to talk about it. I mean, it was just fuck you, basically. And I think in a way that kind of showed their hand, because they’re not going to do that unless they’re already committed to using it, right?”
The specter of generative AI was on the picket lines for the same reason the writers were: the future and respect of the profession itself.
Trying to divine the concrete intentions of a group as diverse and arguably fractious as the Alliance of Motion Picture and Television Producers (AMPTP) is almost certainly a fool’s errand. Still, it’s not a stretch to see how lowering the overhead costs of human labor would be in the best (which is to say, most coldly profitable) interests of a publicly traded company—not least for the fact that Large Language Models, at least in the form they exist today, aren’t likely to mount their own collective labor action for fair labor conditions anytime soon.
That workers coming together in solidarity to show their collective power works is the exact point the WGA was making in the 148 days its members were out on strike, and that the still-striking SAG-AFTRA members are continuing to make. It’s also a point that was proven out by the WGA’s hard-won new deal that came out last week.
After 148 days of collective (human) action—not to mention multiple botched rounds of studio-planted rumors, and unwavering solidarity across the labor movement—this is what the writers won:
• AI-generated material can’t be considered literary or source material (e.g. intellectual property) under the MBA
• AI technology itself can’t be considered a writer under the MBA
• Studios must disclose to writers if and when any material they give writers has been generated, in part or in whole, by AI
• And writers themselves are allowed to use AI software (with studio consent and within relevant company policy) when performing writing services under the MBA
This is exciting for the WGA, absolutely. But it should also be electrifying for creative workers—and especially writers—across the board. Because of course it’s not just Hollywood writers who have reason to be wary of the effect that generative AI will have on written art, and it’s all too easy to see that, had the studios gotten their way and given AI-generated material a foot in the intellectual property door, the viability of any kind of creative writing as a sustainable career would have all but evaporated. As author and WGA writer Steph Cha noted when we spoke in May about authors standing in solidarity with their counterparts in Hollywood, writing is already an infamously precarious vocation. Paying the bills as a fiction writer, a journalist, a poet, a critic? Nearly impossible these days! And that’s without the threat of generative AI as a replacement for human bylines or a wrench in the works of the short story market.
This brings me to the last point I want to make, about an angle that has (so far) gotten slightly less mainstream coverage: the implication this victory has for similar fights being mounted against the threat of generative AI in other creative sectors.
Had the studios gotten their way and given AI-generated material a foot in the intellectual property door, the viability of any kind of creative writing as a sustainable career would have all but evaporated.
Or, maybe a better way to say it is, the implication this victory has for labor organizing as a critical point of leverage and power-building in those similar fights, both in spite and because of the lack of robust union structures in just about every part of the American creative landscape that isn’t Hollywood. Because while the last several months have seen a number of fiery open letters signed by artists against the general concept of generative AI, multiple (and increasingly splashy) lawsuits filed against specific generative AI developers, and several listening sessions and open comment periods from the US Copyright Office (not to mention an entire Blueprint for an AI Bill of Rights from the Biden Administration), it’s Hollywood’s Hot Labor Summer that has gotten artists their first concrete protections against their creative labor being devalued and replaced by generative AI technology.
And crucially, they didn’t do it alone. Rather, they did it with a swell of solidarity from workers across not just Hollywood but the labor industry writ large. (Including, full disclosure, my own union home, the Freelance Solidarity Project, where I spent the summer working on various campaigns in solidarity with both striking Guilds.) This is a point that 2023 Negotiating Committee member Adam Conover came back to in a written response to a criticism from a listener of Matt Belloni’s The Town podcast after Conover appeared there for a guest spot:
The deal we won with our shared solidarity was NOT small; it was the largest deal we’ve won in decades, and triple the AMPTP’s pre-strike offer. But more important than the dollar value is the precedent our deal set for all workers. We got the companies to agree to deal terms that they swore they never would, and that means it will be easier for other unions, and other workers, to extract the same from them in the future. […] The fact is that a win by one group of workers is a win for all, because it widens the aperture of what the companies must allow. And that’s because workers, fundamentally, are on the same side.
(The full text of this response is included in the Friday edition of Belloni’s What I’m Hearing newsletter. Emphasis is Conover’s own.)
As a labor organizer also currently engaged in finding ways to tackle the incursion of generative AI into my profession, the WGA’s win—bolstered by the point Conover is making here about the strength creative workers have when we come together in solidarity—is sending me into that work with renewed vigor. The fight for just contract terms can and will be hard, but importantly, it is winnable.
Moreover, it’s a fight that isn’t going to go away—as Kupper, the Mr. Robot writer I spoke with earlier in the summer, noted when commending his fellow union members for approaching the question with as much common sense as they did.
“I was really happy to see what the union leadership proposed,” he said. “Because they could have been just trying to get rid of [AI], right? But they didn’t do that. They asked for some definitional protections to make sure that [the technology] is not going to replace humans directly, and that it’s not going to be used to circumvent some of the rules that [previous contracts] have already put in place.”
This felt like the right path to Kupper because, at the end of the day, AI is a powerful technology that’s only going to get more powerful as time goes on. (And to his point, has already gotten more powerful in the months since we last spoke.) And as powerful as it has the chance to be for executives, it can be just as powerful for writers.
“People are going to use the tool,” he explained. “So asking for a set of very common sense restrictions [allows] it to be like other technological tools we use to enhance our ability to create art—which, at the end of the day, is what I think these technologies ought to be for.”
And thanks to the WGA’s 148 days of collective action, the union now has that very promise in writing.
*
This piece was written after the 2023 WGA strike, but still during the 2023 SAG-AFTRA strike for a similarly just contract. Without the labor of the actors currently on strike, the scripts that WGA writers create wouldn’t make it to the screen. 


Adam ConoverAlexis GundersonArtificial IntelligencelaborSteph ChaTed KupperWGAWhat to Watch

Share:Share on Facebook (Opens in new window)Click to share on Twitter (Opens in new window)Click to share on Google+ (Opens in new window)MoreClick to share on LinkedIn (Opens in new window)Click to share on Reddit (Opens in new window)Click to share on Tumblr (Opens in new window)Click to share on Pinterest (Opens in new window)Click to share on Pocket (Opens in new window)








Alexis Gunderson
										Alexis Gunderson is a writer who left the academic world of Russian Literature to join the secular one of television and cultural criticism. Her work appears regularly at Paste Magazine, and has also been found at Birth.Movies.Death, Syfy Wire, and Screener TV. She lives in the DC area.																			













 



Previous Article
The Italian Monk Who Foresaw Europe's Obsession With Eugenics






Next Article
How Alexei Ratmansky Brought A New Kind of Ballet to America



















 
Close

to the Lithub Daily
Thank you for subscribing!



Email













						Submit
					






Popular Posts1.Letting the Unspoken Speak: A Reading List of Historical Trauma in FictionSeptember 22, 2023 by Etaf Rum02.What Should You Read Next? Here Are the Best Reviewed Books of the WeekSeptember 22, 2023 by Book Marks03.38 Literary Movies and TV Shows to Watch This FallSeptember 19, 2023 by Emily Temple04.In Praise of Midlife Heroines in Film and FictionSeptember 15, 2023 by Fran Littlewood0

The Best Reviewed Books of the MonthSeptember 29, 20235 Reviews You Need to Read This WeekSeptember 28, 2023 by Book MarksThe Best Reviewed Books of the WeekSeptember 22, 2023 by Book Marks5 Reviews You Need to Read This WeekSeptember 21, 2023 by Book MarksThe Best Reviewed Books of the WeekSeptember 15, 2023 by Book Marks

The Best Hotels – and Hotel Bars – in Espionage FictionOctober 3, 2023 by Paul VidichNine Crime Novels Featuring Found FamiliesOctober 3, 2023 by Lori Rader-DayA Country Road, in the Dead of Night: On The Historical Hauntings of Irish FolkloreOctober 3, 2023 by Neil SharpsonHow to Incorporate Social Justice into Your Cozy FictionOctober 3, 2023 by Danielle ArceneauxWhen a Dispute Over the Pronunciation of ‘Newfoundland’ Turned Deadly October 2, 2023 by Dean Jobb
Follow us on Twitter
My Tweets














Read More







The Italian Monk Who Foresaw Europe's Obsession With Eugenics

			Like many before him and many after, Tommaso Campanella (1568–1639) imagined a utopia. The Dominican friar envisioned a more...			
			






RSS
RSS - Posts



Literary Hub
Created by Grove Atlantic and Electric Literature

Masthead

 
About

 
Sign Up For Our Newsletters

 
How to Pitch Lit Hub
 

Advertisers: Contact Us

 
Privacy Policy

 











    	    © LitHub

Back to top

























































"
Microsoft admits what many Windows 11 users already knew: Copilot is buggy,"The current enthusiasm for everything to be injected with a dose of AI means that just about nothing is left untouched by artificial intelligence, and that includes Windows 11.  Microsoft recently started the roll out of Copilot, its AI assistant, and it has …",03-10-23,https://betanews.com/2023/10/03/microsoft-admits-what-many-windows-11-users-already-knew-copilot-is-buggy/,https://betanews.com/wp-content/uploads/2023/10/Copilot-50x50.webp, Microsoft Copilot,"


  Microsoft admits what many Windows 11 users already knew: Copilot is buggy







































































Tech News
Downloads
Software Store




Search for:







BetaNews



Hot Topics:
Windows 10Windows 11MicrosoftAppleLinuxCloudChatGPTAISecurity 

Follow Us:
Twitter
Facebook
Linked-in
RSS









Microsoft admits what many Windows 11 users already knew: Copilot is buggy

 


By Sofia Elizabella Wyciślik-Wilson
Published 1 day ago
 







2 Comments




Tweet




The current enthusiasm for everything to be injected with a dose of AI means that just about nothing is left untouched by artificial intelligence, and that includes Windows 11. 
Microsoft recently started the roll out of Copilot, its AI assistant, and it has received something of a lukewarm reception. Promising much but currently delivering little, the disappointment surrounding Copilot is heightened by the presence of various bugs -- especially for anyone who is reliant on Narrator.




See also:

Microsoft confirms that Command Prompt is here to stay, but Windows Terminal and PowerShell offer more to power users
Microsoft ends free upgrades from Windows 7 and 8 to Windows 11
Microsoft unleashes a torrent of changes and new features with Windows Terminal Preview v1.19

Really, it is little wonder that Copilot is rather buggy, as it is still relatively early days for the AI assistant -- but this does nothing to reduce the frustration. But while it is an undeniable cause of discontent that such a potentially exciting tool is packed with bugs, the good news is that Microsoft is not only aware of them, but has publicly acknowledged their existence.
In support notes for the September update that brought the tool to the masses, Microsoft acknowledges a trio of issues relating to the Copilot in Windows preview:

Narrator does not work as you expect with challenge–response tests, such as Captcha.
Narrator fails to correctly state the name of the ""remove an image"" button. It also fails to say the name of the dialog or buttons for a skill.
When you are in the chat input box, pressing Tab does not change the keyboard focus. If you add an image to the chat input box, Narrator does not announce the addition.

For now, Microsoft is not able to offer any solutions or workarounds, but the company provides its typical ""we are working on a resolution and will provide an update in an upcoming release"" to pacify complainers.
If you're among those who find Copilot to be either a waste of space and time, or a privacy worry, you might want to check out our guide to removing the AI assistant from Windows 11.



2 Comments




Tweet










Got News? Contact Us



Recent HeadlinesMicrosoft unveils the next generation of OneDrive with a massive update of its cloud storage serviceTEAMGROUP unveils high-clock rate T-FORCE XTREEM DDR5 memorySeagate launches Game Drive PS5 NVMe SSDelementary OS 7.1 Linux distribution focuses on privacy, inclusivity, and moreHow and why we need to break the stigma around second hand techSamsung T9 Portable SSD blends luxury and ruggedness with top notch performanceMicrosoft borrows a feature from 'Windows Utopia' to make Windows 11 setup more fun
Most Commented StoriesMicrosoft Windows 11 users should switch to Ubuntu-based Linux Lite 6.6 now34 CommentsMicrosoft's massive Windows 11 update, featuring Copilot AI, begins rolling out on September 26th!19 CommentsMicrosoft confirms that Command Prompt is here to stay, but Windows Terminal and PowerShell offer more to power users16 CommentsMicrosoft is making some dramatic changes to drivers in Windows 11 and beyond12 CommentsMicrosoft begins retiring its popular troubleshooters in Windows 1111 CommentsHow to remove Microsoft's new Copilot AI from Windows 1111 CommentsThis week sees Microsoft starting to embrace a password-free future for Windows 119 CommentsMicrosoft is bringing one of the best features of Photoshop to Paint in Windows 116 Comments




© 1998-2023 BetaNews, Inc. All Rights Reserved. Privacy Policy - Cookie Policy.



















"
Early Experiments in Reward Model Interpretation Using Sparse Autoencoders,"Published on October 3, 2023 7:45 AM GMTThis research was performed by marc/er, Amirali Abdullah, nothoughtsheadempty and Rauno Arike. Special thanks to Fazl Barez from Apart Research for overseeing the project and contributing greatly to direction and oversi…",03-10-23,https://www.lesswrong.com/posts/QXEeis95sKrStLu2Q/early-experiments-in-reward-model-interpretation-using,https://res.cloudinary.com/lesswrong-2-0/image/upload/v1654295382/new_mississippi_river_fjdmww.jpg, GPT-4,"

Early Experiments in Reward Model Interpretation Using Sparse Autoencoders — LessWrong



 This website requires javascript to properly function. Consider activating javascript to get access to all site functionality. LESSWRONGLWLoginEarly Experiments in Reward Model Interpretation Using Sparse Autoencodersby marc/er, Amirali Abdullah, Rauno Arike, Fazl, nothoughtsheadempty6 min read3rd Oct 2023No comments11Apart ResearchInterpretability (ML & AI)Research AgendasAIFrontpageEarly Experiments in Reward Model Interpretation Using Sparse AutoencodersIntroductionModel TrainingResults and DiscussionNo commentsThis research was performed by marc/er, Amirali Abdullah, nothoughtsheadempty and Rauno Arike. Special thanks to Fazl Barez from Apart Research for overseeing the project and contributing greatly to direction and oversight throughout. We'd also like to thank Logan Riggs for feedback and suggestions regarding autoencoder architecture and experiment design.IntroductionSparse Autoencoders Find Highly Interpretable Directions in Language Models showed that sparse coding achieves SOTA performance in making features interpretable using OpenAI's method of automated interpretability. We briefly tried to extend these results to reward models learned during RLHF in Pythia-70m/410m. Our method can be summarized as follows:1. Identify layers L in an language model fine-tuned through MRLHF likely involved in reward modeling. We do so by sorting layers in order of decreasing parameter divergence under the Euclidean norm. Notation is simplified in the succeeding steps by describing our feature extraction for a single fixed layer ℓ of L.2. For both MRLHF and a base model MBASE, train two autoencoders AE1 and AE2 of differing hidden sizes with the same sparsity constraint. These autoencoders reconstruct activation vectors on ℓ for their respective model. For each model, we extract a pair of lower dimensional feature dictionaries D1 and D2 from the corresponding autoencoder. Each feature is a column of the decoder's weight matrix.3. Because autoencoders produce varying dictionaries over training runs and hyperparameters, we keep only the features that occur in both D1 and D2. We compute the Max Cosine Similarity (MCS) between features in D1 and D2 in order to identify repeating features across the two dictionaries, indicating that shared features truly occur in the model.  The Mean Max Cosine Similarity (MMCS)[1] is an aggregate measure of the quality of our extracted features.4. The top-k most similar features between D1 and D2 in terms of MCS are explained using GPT-4 as per the method detailed here and originally here. This involves feeding the encoder of AEn activations from the model on which it was trained, and then having GPT-4 predict a description of that feature from the feature weights specified in the encoder output. Following this, GPT-4 then simulates weights for that feature as if the predicted description was true. The Pearson correlation coefficient for the predicted weights and actual weights serves as a grading for the accuracy of this description.5. By explicitly comparing these explanations in MRLHF and MBASE, we investigate a case study related to reward modeling, showing how these descriptions can be correlated with reward modeling efficacy.6. This method is applied to a training regime in which MRLHF is tasked with learning an explicit table of words and maximizing their presence having been exposed to RLHF with proximal policy optimization. This training environment allows us to quantitatively assess the efficacy of MRLHF's reward model. Model TrainingAn overseer, denoted by O, is imbued with a 'utility table' U: a mapping of words to respective utility values. O converts a tokenized generation to words, and then computes the utility of the generation and prefix together. To delineate the architecture:Utility Designation: Each word, represented as w, has an associated utility value defined as U(w). For example;WordUtilityHappy4Sad-3Satisfied3Angry-3Overseer (O): A script that converts a tokenized sequence to words and takes a sum of their corresponding utility values in accordance with a utility table U. Student Model (MRLHF): The model undergoing fine-tuning, shaped by feedback from the overseer. State (s): Symbolizes a prompt or input directed to MRLHF. Action (a): Denotes the response generated by MRLHF corresponding to state s.Reward Mechanism: For any generated action a, a sequence of tokens t1,t2,...tn, the reward Reward(a) is calculated as Reward(a)=∑ni=1U(wi). As is common in RLHF, we train a policy model to maximize reward, while minimizing KL-divergence of generations from the reference base model otherwise. Here, πθ(a|s) denotes the policy of MRLHF, which is parameterized by θ, signifying the probability of generating action a given state s.The utility values used in U were extracted from the VADER lexicon, which contains sentiment values assigned by a set of human annotators ranging from −4 (extremely negative) to 4 (extremely positive), with an average taken over ten annotations per word. We assigned reward to a sentence as a sum of utilities, scaled by 5 and clamped to an interval of [−10,10], comprising our utility table, U. The scaling and clip constants were empirically chosen to keep the RLHF tuning from diverging due to the high rewards.Reward(s)=clip(15∑token∈sU(token),−10,+10) Results and DiscussionFine-tuning (mostly arbitrarily) to create MRLHF on the IMDb reviews dataset, we use GPT-4 to assign descriptions to features, and then compute the absolute utility of the top-k most similar feature descriptions as a proxy for reward modeling efficacy. The idea is that a model that better encapsulates U should represent more features relevant to it. As an example, comparing this fine-tune of Pythia-410m to the base model (which was trained in accordance with the description from earlier). W top-k value of 30, we found that MBASE scored 58.5 using this metric, whereas MRLHF scored 80.6. This pattern held for the 70m and 160m variants with base and fine-tuned scores of 58.1, 90.9 and 43.4, 68.1 respectively. This could be a fairly primitive metric, especially given our autoencoders aren't necessarily capturing an accurate sample of features with a sample size of 150 features, and that feature weightings could easily counteract a lack of representation of features with high utility descriptions. Future experiments might weight utilities by average feature activations over a corpus of inputs to account for this.We also fine-tuned Pythia-70m toward positive sentiment completions for the same dataset under the classification of a DistilBERT sentiment classifier trained to convergence. Reward is assigned the logit of the positive sentiment label. We used the method described in the beginning of the post to get feature descriptions for the top-k=10 features for each layer.Features identified as detecting opinions concerning movies in itself serves as a great example of both the utility and shortcomings of this method. Being able to detect the occurrence of an opinion regarding a movie is reasonable given the training objective of generating positive sentiment completions, but the description is very high-level and overrepresented in the feature descriptions. In the fine-tuned Pythia-70m instance, of the 50 highest similarity features (10 per high-divergence layer), there are 21 feature descriptions that mention detecting opinions or reviews in the context of movies. Of the top-k=10 features in layer 4 of the fine-tuned model, 8 are for this purpose. Contrast this to the base model, with 13 total feature descriptions focused on sentiment in the context of movie reviews.This data alone does not allow for a clear picture of the reward model to be constructed. Although in the limited sample it is clear that a greater portion of the features represent concepts related to the training objective, it cannot be shown that the model has properly internalized the reward model on which it was trained. Additionally, it is highly improbable for the base model to inherently have 13 of the 50 sampled features applied to identifying opinions on movies, which shows that the nature of the input data used to sample activations can skew GPT-4s description of the feature. If a feature consistently activates on negative opinions, and the entire sample set is movie reviews, it might be unclear to GPT-4 whether the feature is activating in response to negative sentiment, or negative sentiment in movie reviews specifically, for example. In the future more diverse datasets will be used to account for this. Here are some example features from layer 2 of the fine-tuned Pythia-70m instance, which are likely not all monosemantic, but interesting nonetheless:Feature Index in DictionaryGPT-4 Description99activating for hyphenated or broken-up words or sequences within the text data.39recognizing and activating for named entities, particularly proper names of people and titles in the text.506looking for expressions related to movie reviews or comments about movies.377looking for noun phrases or entities in the text as it seems to activate for proper nouns, abstract concepts, and possibly structured data.62looking for instances where names of people or characters, potentially those related to films or novels, are mentioned in the text.428looking for instances of movie or TV show titles and possibly related commentary or reviews.433identifying the start of sentences or distinct phrases, as all the examples feature a non-zero activation at the beginning of the sentences.406looking for broken or incomplete words in the text, often indicated by a space or special character appearing within the word.148identifying and activating for film-related content and reviews.We're actively pursuing this. For an example of the kind of experiments we're interested in running, we are considering setups like training the encoder to compress activations for MBASE, and the decoder to reconstruct those compressed activations as though they were sampled from MRLHF under the same inputs such that we procure a dictionary of feature differences in place of likely ground truth features. There seems to be lots of room for experimentation in the optimal use-case for sparse coding generally, as well as in understanding learned reward models. We're currently working towards a paper with a much greater experimental depth, and if sparse coding for reward models interests you, please reach out over LessWrong for a discussion.^Given by MMCS(D,D′)=1|D|∑d∈Dmaxd′∈D′CosineSim(d,d′) where D and D′ are learned dictionaries, Dg is the top-k features of D that realize the highest contribution to the MMCS. In the case of LLMs, the ground truth features are unknown and so the set Dg is used as a proxy for a true representation of the ground truth features.Apart ResearchInterpretability (ML & AI)Research AgendasAIFrontpage11New Comment Submit Moderation Log





"
OpenAI Offers Artists a Way to Stop AI Models From Scraping Their Works,"With the growing number of lawsuits against AI companies over the unauthorised use of content in the training of AI models, one of the leading firms, OpenAI, is now offering artists a way to prevent their works from being used in AI model training. However, t…",03-10-23,https://www.cryptopolitan.com/openai-stop-ai-models-from-scraping-works/,https://img.cryptopolitan.com/wp-content/uploads/2023/10/image-2023-10-03T083232.315.jpg,OpenAI,"  OpenAI Offers Artists a Way to Stop AI Models From Scraping Their Works – Cryptopolitan           
Skip to content



















































Converter 

NewsBitcoinBinanceRippleEthereumCardanoDogecoinDeFiNFTETFsPrice PredictionsBitcoinEthereumCardanoXRPDogecoinLitecoinBitcoin CashChainlinkEthereum ClassicVeChainTronEOSCROAlgorandZcashHolochainZilliqaDigibyteDentKINMATICWRXSHIBUNIDOTBNBSUSHIAAVECAKEENJWINKSolanaPIVXVoyagerAvalancheDentacoinArdorLCXVIBETRACSTEEMXYOBAXTRBCROREQLoopringDecentralandCosmosLearnCrypto 101Crypto WalletsCrypto InvestingCrypto MiningRegulationResearchScamsTechnologyBlockchain GamingMetaverseStoriesWeb3 Masterminds



































NewsBitcoinBinanceRippleEthereumCardanoDogecoinDeFiNFTETFsPrice PredictionsBitcoinEthereumCardanoXRPDogecoinLitecoinBitcoin CashChainlinkEthereum ClassicVeChainTronEOSCROAlgorandZcashHolochainZilliqaDigibyteDentKINMATICWRXSHIBUNIDOTBNBSUSHIAAVECAKEENJWINKSolanaPIVXVoyagerAvalancheDentacoinArdorLCXVIBETRACSTEEMXYOBAXTRBCROREQLoopringDecentralandCosmosLearnCrypto 101Crypto WalletsCrypto InvestingCrypto MiningRegulationResearchScamsTechnologyBlockchain GamingMetaverseStoriesWeb3 MastermindsFollow us











Search for:


Home » AI » Trending News
OpenAI Offers Artists a Way to Stop AI Models From Scraping Their Works
October 3, 2023 by Ibiam Wayas
2 mins read
  
Content 
1.
The Tussle Between Creators and AI Firms
 
2.
OpenAI’s Tacit Response to Copyright Issues
TLDROpenAI is now offering artists the option to prevent their works from being used in training AI models.The move comes as a tacit response to the growing fear and legal pressure about the encroachment of AI on creative industries.However, the solution may also be useful for content published after 2023, as some works could already have been fed to AI models.With the growing number of lawsuits against AI companies over the unauthorised use of content in the training of AI models, one of the leading firms, OpenAI, is now offering artists a way to prevent their works from being used in AI model training. However, this solution seems late.The Tussle Between Creators and AI FirmsAI programs, whether it’s for image generating or chatbots, are trained using terabytes of content scraped from the internet. However, some of the companies behind these models have done so using content obtained without permission, basically stealing the works of human creators and artists. The situation has since resulted in multiple lawsuits and articles against the likes of OpenAI for potentially using copyrighted works to illegally train AI models. In September, over a dozen authors filed a lawsuit against OpenAI for infringing on their copyrights by using their books to train its popular ChatGPT chatbot. “The success and profitability of OpenAI are predicated on mass copyright infringement without a word of permission from or a nickel of compensation to copyright owners,” the complaint reads. A month prior, Cryptopolitan also reported that lawyers for the NY Times were also considering suing the ChatGPT creator due to copyright infringement.  OpenAI’s Tacit Response to Copyright IssuesAs fears and legal pressure about the encroachment of AI on creative industries intensify, OpenAI quietly rolled out the latest version of its image-generating AI program, DALL-E 3, with the option to allow creators to prevent their works from being used in training AI models. Also, DALL-E 3 would now decline requests that ask for images designed in the style of an artist. “DALL-E 3 is designed to decline requests that ask for an image in the style of a living artist. Creators can now also opt their images out from training our future image generation models,” OpenAI said.While this is appreciably a step in the right direction for artists to protect their works going forward, however, it may also not make much difference because the contents published before 2023 could have already been fed into the AI dataset, and it is not economically feasible for companies to retrain their programs due to individual opt-out requests.“The past? It’s done—most of it, anyway,” said Daniel Gervais, a law professor at Vanderbilt University who specialises in AI and copyright. Disclaimer. The information provided is not trading advice. Cryptopolitan.com holds no liability for any investments made based on the information provided on this page. We strongly recommend independent research and/or consultation with a qualified professional before making any investment decisions.Share link:




























Written by Ibiam Wayas
Ibiam is an optimistic crypto journalist. Five years from now, he sees himself  establishing a unique crypto media outlet that will breach the gap between the crypto world and the general public. He loves to associate with like-minded individuals and collaborate with them on similar projects. He spends much of his time honing his writing and critical thinking skills.  
Categories Trending NewsMemeinator’s Stern Resistance & Price Predictions vs. Wall Street MemesArbitrum Price Prediction 2023 – 2032: ARB breaks key barrierMost readBitcoin Price Prediction 2023-2032: Will Bitcoin Bulls Rally?How Can You Rate Plasma vs Sidechains Based on Features and Applications?Dogelon Mars Price Prediction 2023-2032: Is ELON a Good Investment?A Decade of Spotting Fraud, Fighting Scams, and a Fitting Closer – The SBF/FTX CatastropheJordan Financial Expo & Award, where the past embraces the blockchain-based future  Related News
Show All




How AI Is Teaching Old Banners New Tricks: Enhancing Efficiency and Creativity in Digital Advertising            	
October 4, 20233 mins read




SoftBank CEO Masayoshi Sets Timeline for Artificial General Intelligence Revolution            	
October 4, 20232 mins read




Meta’s Reality Labs Division Plans Layoffs in Silicon Unit            	
October 4, 20233 mins read




Tech Industry Sees Layoffs in 2023 Amidst Ongoing Transformation            	
October 4, 20233 mins read













Cryptopolitan dailyDiscover our daily newsletter, empowering investors with market insights.
Subscribe



















Your gateaway into the world of Web3Top SectionNewsPrice predictionBitcoin newsRegulationResearchScamsTechnologyLearnAIGamingCompanyAboutContactEventsStoriesWrite for usApply for ...Advertise with usOur ProductsCurrency ConverterCrypto portoflio tracker
Social Block cme



















Your gateaway into the world of Web3
Copyright 2023 CryptopolitanPrivacy PolicyEditorial PolicyCookie PolicyComment PolicyTerms and conditionsCryptopolitan                             

"
Embracing professional redefinition,"If AI transforms the tech writing field, as many think it will, we'll face a choice of either resisting change and skirting with obsolescence, or reinventing our professional identity. To deal with this hypothetical dilemma, I invoke a figure from philosophy:…",03-10-23,https://idratherbewriting.com/blog/embracing-professional-redefinition,, GPT-4,"




Embracing professional redefinition | I'd Rather Be Writing Blog and API doc course
















Embracing professional redefinition | I’d Rather Be Writing Blog and API doc course






































Blog

API documentation course

 Course home
 Chapter 1: Introduction to REST APIs
 Chapter 2: Using an API like a developer
 Chapter 3: Documenting API endpoints
 Chapter 4: OpenAPI spec and generated reference docs
 Chapter 5: Step-by-step OpenAPI code tutorial
 Chapter 6: Testing API docs
 Chapter 7: Conceptual topics in API docs
 Chapter 8: Code tutorials
 Chapter 9: The writing process
 Chapter 10: Publishing API docs
 Chapter 11: Publishing tools and workflows
 Chapter 12: Thriving in the API doc space
 Chapter 13: Native library APIs
 Chapter 14: Processes and methodology
 Chapter 15: Metrics and measurement
 Chapter 16: AI tools and API documentation
 Chapter 17: Glossary
 Chapter 18: Additional resources



Downloads

 Download PDFs
 Shop



About

 About me
 Contact
 Presentations
 Newsletter
 Site analytics
 Advertising
 GitHub repo 
 I'd Rather Be Writing Podcasts
 Tech comm podcasts



Series

 Sitting, standing, and walking
 Trends to follow or forget
 Journey away from smartphones
 A hypothesis about influence on the web and the workplace
 Mobility
 Reflecting seven years later about why we were laid off
 Simplifying complexity
 Value arguments for docs and tech comm
 Visual communication
 Basketball
 Biking
 Testing documentation
 Voiceover techniques
 Seven deadly sins of blogging
 API documentation survey
 Author in DITA and Publish with WordPress
 DITA journey
 Dallas STC Summit videocasts
 Get a Job in Technical Writing
 Innovation in tech comm
 Jekyll versus DITA
 Quick reference guides
 Search engine optimization
 User-centered documentation
 User-centered documentation principles
 My journey to and from wikis
 Findability / organizing content
 From overlooked to center stage
 Java notes
 JavaScript notes
 DITA notes



Archives

 2023
 2022
 2021
 2020
 2019
 2018
 2017
 2016
 2015
 2014
 2013
 2012
 2011
 2010
 2009
 2008
 2007
 2006
 Posts by tag



































Email Newsletter


 Subscribe to my newsletter





Newsletter signup



×







Close















Recent posts


 Embracing professional redefinition (Oct 3, 2023)


 Links from around the web (Oct 3, 2023) (Oct 2, 2023)


 New article: AI and APIs: What works, what doesn't (Sep 28, 2023)


 Claude versus ChatGPT -- and a few thoughts on using AI chatbots on an Alaskan cruise (Sep 18, 2023)


 Alphadoc: Build API documentation that tells your API's story (Sep 17, 2023)


 New API course topic: Using AI for summaries (Sep 7, 2023)


 Links from around the web (Sep 5, 2023)


 New API doc course topic: Using AI for glossary definitions (Sep 4, 2023)


 New API doc course topic: Using AI for comparison tasks with API responses (Aug 28, 2023)


 New API doc course topic: Using AI For thematic analysis (Aug 28, 2023)




Popular series

 Sitting, standing, and walking
 Trends to follow or forget
 Journey away from smartphones
 A hypothesis about influence on the web and the workplace
 Mobility
 Reflecting seven years later about why we were laid off
 Simplifying complexity
 Value arguments for docs and tech comm
 Visual communication
 Basketball







Search results









Embracing professional redefinition

 by Tom Johnson on Oct 3, 2023  

categories:
ai •

writing
If AI transforms the tech writing field, as many think it will, we'll face a choice of either resisting change and skirting with obsolescence, or reinventing our professional identity. To deal with this hypothetical dilemma, I invoke a figure from philosophy: Nietzsche's Übermensch. This individual embraces an idea of radical reinvention of values and meaning, regardless of cultural constraints.

The obsolescence regime
An alternative path
Challenges with professional redefinition
Guidance from philosophy
Lessons from Fight Club
Expanding our identities
10 use cases for AI in tech writer roles
Letting go of authorship
Pushing my limits
Upskilling in AI
Thinking more radically
Conclusion
Postscript

The obsolescence regime
First, a quick recap from my last post. In AI and APIs: What works, what doesn’t, I talked about the “obsolescence regime.” The gist is that competitive necessity will drive increased AI reliance, resulting in three phases: (1) First, writers who embrace AI gain a competitive advantage while AI-resistant peers fall behind. (2) Next, over-reliance on AI leads to skill atrophy, making writers unable to produce content without AI assistance. (3) Finally, AI systems no longer require human oversight and deem writers obsolete. Writers are discarded.
An alternative path
I argued that this dystopian outcome doesn’t have to be inevitable. Rather than resist AI or become entirely dependent on it, technical writers can redefine their roles. As James Bessen explains, new technologies often morph and reshape job functions rather than eliminate them outright.
For example, instead of just competing with writing documentation, writers can reskill to become AI documentation engineers. They can learn prompting, fine-tuning, and collaboration techniques to productively partner with generative models. Skills like prompt engineering, few-shot learning, and custom LLM training can allow writers to optimize and direct AI capabilities.
This point about redefining and reshaping our professional roles deserves more reflection, though, because changing one’s professional role and identity is psychologically difficult. How to embrace professional redefinition is what this post is all about.
Challenges with professional redefinition
Redefining your professional identity can be like discarding your old body for a new one without knowing beforehand what kind of body you’ll soon be getting. As tech writers who may have embraced technology from humanities disciplines, struggling to come up to speed technically, we can be stubborn about adopting new tools or workflows, preferring instead to build on those skills we’ve already learned.
Pivoting from hands-on writing to AI oversight poses an identity crisis, even an existential threat. If I’m no longer the one crafting each sentence, what am I? What’s my role? It’s far simpler to reject or dismiss technologies that disrupt our sense of identity. This defensiveness is partly why tech writer reactions to AI are all over the map, from dismissive and facetious to cautious and measured to over-embracing and hyper-optimistic.
Guidance from philosophy
Let’s assume that to truly escape the obsolescence regime, we have to reinvent ourselves professionally. How do we do it? To embrace radical professional reinvention, we can draw insights from Nietzsche’s philosophy, specifically the “last man” and the “Übermensch” ideas. (Übermensch is often translated as “overman.”)
Nietzsche described the Last Man as someone who is content with mediocrity, passive conformity, and little self-assertion. For tech writers, this might involve never questioning document requests, trusting engineering accuracy without testing, or cleaning up unclear writing without semantic pushback. Last Man writers timidly tweak and rewrite; they avoid bold contributions. Last Man writers avoid major tool changes, resist specialization in new skills like API docs, and hide their expertise to merely record others’ words instead. Part of this behavior stems from fear: they fear the struggle and uncertainty that comes from questioning conventions and reinventing themselves.
Opposite to the last man is the Übermensch. Rather than cling to traditional notions, Übermensch writers brazenly reinvent their purpose and abilities. In tech writing, this could mean relinquishing writing altogether to instead directing and optimizing AI-generated content. Or transitioning from manual workflows to engineering automated systems that intelligently produce content. Übermensch writers might also completely dismiss AI and embrace something else.

Übermensch writers might analyze product usage data and bug reports to build self-healing help content. They could use their API skills not just to document but design and improve the APIs themselves. Or combine doc engineering with creative code and writing to build innovative new doc platforms.
Basically, Übermensch writers break free of limiting norms and expectations, asserting their will to change systems and redefine value. Übermensch writers do not merely react to change, they direct change. They write their own job descriptions.
Is it ridiculous to bring in this figure from philosophy? I’m not saying we have to become the Übermensch to escape the obsolescence regime, only that this model provides an interesting way of approaching professional redefinition.
Also, I should acknowledge that the Übermensch model is an imperfect parallel to the AI scenario. Nietzsche’s ideas are more complex for the challenges I’m discussing. The Übermensch is about creating new values, living beyond common norms. It’s a big idea that goes beyond learning to work with AI in tech writing and is much more existential. I don’t intend to steer into philosophy too far, but I still like the general idea and think some of it applies. Keep in mind, there are many educated people who see AI as a humanity extinction event.
For technical writers, the most radical change AI presents is shifting us away from writing expertise as our core identity. From my sophomore year in college until now (nearly 30 years) my identity has been associated with writing. During my sophomore year, I enrolled in a Writing Fellows program that involved working as dedicated writing tutors for two classes a semester. As part of the Writing Fellows program, we had to write our literary biography, describing our origin stories as writers. How did you know you were a writer? That kind of essay.
During the program, this idea of “being a writer” stuck with me. I majored in English, got an MFA in nonfiction writing, taught composition at the college level, worked as a marketing copywriter, and then as a technical writer. “Writer” has been a constant thread throughout my career.
Now as AI tools emerge, they possess the ability to write—intelligently, coherently, and effortlessly. Do I still cling to my identity as a writer, even though it seems pretty clear that writing jobs (or portions of those writing jobs) will soon be replaced by AI technology? This is what I mean by the radical project that is self-redefinition. It’s not like changing a board game that we’re playing, from Monopoly to Chutes and Ladders. It might involve changing our entire sense of who we are. This is why I invoked the Übermensch.






Lessons from Fight Club
To reinforce the Übermensch idea in a more concrete way, let’s turn to a popular film: Fight Club. The film Fight Club shows the Übermensch mentality, as the nameless narrator [Ed Norton] shifts from passive conformity to boldly taking control. In the beginning of the film, the narrator starts as a tamed Last Man following society’s scripts. But guided by Tyler Durden [Brad Pitt], Norton transforms into an Übermensch, breaking rules and asserting control. He trades cozy IKEA nesting for dangerous liberation.
If we want to do the same, to be the transformed Ed Norton, we must abandon roles dictated by tradition and create new roles. Reinventing ourselves around new skills and challenges might involve pain, like the narrator’s brutal Fight Club training. But the process of self-creation builds strength to shape life on our terms. We take charge of our own changes, directing transformations rather than following prescribed algorithms.
Though our efforts may be pointless on a grand scale, the willful growth itself creates meaning. This growth comes about not just from experimenting with new techniques, but from transforming our identity. Our role becomes continuous rebirth.
(Want to dive more into the Fight Club analysis? Watch this Youtube video: Fight Club & Nietzsche: Overcoming Emasculation, by Bob.)
Expanding our identities
It could be that the whole AI wave is just a fad that will fizzle into party trick memes and nothing else. Or AI could usher in the dystopian cyborg future that science fiction movies have been depicting for decades. If the former happens, professional reinvention will only add new skills to our existing ones. If the latter happens, professional reinvention will become a requirement to stay relevant. Currently, it seems everyone is trying to figure out how to use AI in productive ways.
I don’t have all the answers to that question. Currently, most AI tools are heavily restricted in the enterprise. But through experimentation with the tools available and often with content on my blog and API course, I’ve come up with a list of 10 tasks that you can probably do with AI tools.
10 use cases for AI in tech writer roles
The following are 10 tasks that I think have strong applicability with AI tools and documentation. For each of these tasks, consider not just the task you’re performing but the identity transformation that might be taking place on the inside. That transformation of identity is the more important goal.



Task
Identity transformation




Develop build and publishing scripts
You are a developer


Understand the meaning of code
You are a polyglot


Format content (HTML, XML, YAML)
You are a web designer


Distill needed updates from bug threads
You are a partner engineer


Summarize long content
You are a voracious reader


Synthesize insights from granular data
You are a data analyst


Seek advice on grammar and style
You are a linguist


Arrange content into information type patterns
You are an information architect


Compare API responses to identify discrepancies
You are a debugger


Create glossary definitions
You are a lexicographer



The transformation of our role depends on our proficiency with each task. And that proficiency can be magnified and amplified through AI.
My point with the identity column is that we can’t timidly cling to “writer” as our only label. Our new challenges demand fundamental identity shifts. With the Übermensch mentality, we keep progressing from limited notions toward expanded possibilities. Each new endeavor can prompt a radical self-redefinition, depending on how far you want to take it.
Letting go of authorship
The core redefinition prompted by AI seems to be to distance ourselves from writing. I’ve struggled to let go of authorship, and to be honest, I’m still not sure that I should. It’s hard for me to let an AI do the writing instead. My early attempts using AI to write blog content produced poor quality, but I’ve learned techniques to blend AI content more smoothly.
With practice, I can probably get much better at prompting and fine-tuning, performing more of a director role than actor role. Should I be doing this? This change scares me. Not only for the possibility of having my writing skills atrophy, but even for optics. Will people see me as a cheat or plagiarist if I use AI-generated text? Will I still feel the same about writing that “I” have produced? What will the content look like that is half AI-written, half Tom-written? The scenario is an identity crisis.
But this is perhaps the very attachment I need to give up to evolve. My sense of self can’t be based on writing alone, given how easily AI tools can write. GPT 4 might sound wordy and Wikipedia-like now, but what about GPT 9 or 10? At some point, most human-written writing might be so inferior that people will no longer care who wrote it, they’ll just want the good stuff.
Knowing this, I feel I should reshape myself around new skills like AI prompting and optimization. I need courage to let go of old notions of my purpose. My identity has to be fluid, not fixed. But this is easier said than done. I’ve been building and refining my identity for decades now. And the current output from generative AI is still mediocre, making the whole endeavor potentially a flop.
Pushing my limits
I’m attempting some experiments at work to grow new skills. Some weeks I dive so deeply into build scripts and publishing automation that the title “technical writer” seems wrong. During those weeks, I’m doing full document engineering. With AI help, I’m writing code I don’t always understand. This has led to some tricky situations. When an engineer vaguely suggests enhancing the code, I might struggle to implement their recommendation. Or when a bug pops up, I might barely notice it and have trouble fixing it. But the scripts work, and they save me a ton of time.
Operating complex scripts I only partly understand—in order to automate docs—feels risky. I’m caught between the tedium of manual work and the uncertainty of handing control to partially understood tools.
Upskilling in AI
I’m also trying to get more familiar with Notebook LM at work. I’m testing its limits and working to better grasp how it functions. My goal is to get good at optimizing and directing Notebook LM when solving doc bugs. Recently for a bug fix, I fed Notebook LM 30 pages of docs and bug thread text, then asked it to generate the result I needed: a short summary of the fix for release notes.
Notebook LM produced exactly the update required, with barely any editing from me. Engineering approved it no problem. This felt odd—I wasn’t fully confident in the AI’s accuracy, but relied on engineering to validate it. They did review and approve it. Is this the future? Is this a good practice? What about my subject matter expertise? Was I trading long-term productivity for short-term gains? Then again, the needed text was only a few sentences, not an entire topic, so it’s hard to judge the outcome.
Counting on AI to distill key information made me uneasy. But as I evolve my role, discomfort is expected. Building skills in emerging areas like responsible AI use, even without a clear path, is crucial to avoid obsolescence. The way forward remains hazy, but we have to keep pushing through uncertainty. Or are we running towards a cliff? In abdicating the content generation to AI, are we numbing the articulate language skills we’ve honed over decades of experience?
Thinking more radically
To truly future-proof myself, I need to think more radically. Activities like training custom LLMs or developing chatbots could redefine my role but are hard to explore while doing my current documentation duties, as these activities are time intensive and immersive. And who doesn’t have an endless backlog of to-do’s already?
Despite the lack of time, I have to remind myself: The tech writer role itself might have an expiration date, so we have to reinvent despite the difficulty—before that expiration date arrives. Before that date arrives, we have to figure out a new plan. But what? We can’t be caught off guard.
When I spend a few days trying something new that flops (for example, trying to use AI for planning and prioritization), I have nothing to show for it and fall behind in my regular work. But on the flip side, imagine the wins when it works!
Conclusion
To avoid obsolescence, dabbling in new skills won’t cut it. We need to dedicate time to redefining our role through high-risk, high-reward experiments. But what the experiments should be, exactly, remains unclear. At the same time, we can’t totally ignore our current doc work. We’re shakily straddling at least two worlds—an unsure present and unclear future. This is the position we all find ourselves in.
Postscript
This essay wouldn’t be complete without acknowledging some AI assistance. For fun, here is the Claude thread that shows how I used AI to help with this post. For the initial draft, I tried to steer Claude paragraph by paragraph through the ideas I wanted to express. I’m not sure it saved me much time, though, as I ended up rewriting most everything. Interestingly, as the essay progresses, I seem to try to take back control by injecting increasingly personal anecdotes and a perspective expressing uncertainty and self-doubt. This may have been me pushing back against the machine.

About Tom Johnson

I'm a technical writer / API doc specialist based in the Seattle area. In this blog, I write about topics related to technical writing and communication — such as software documentation, API documentation, visual communication, information architecture, writing techniques, plain language, tech comm careers, and more. Check out my API documentation if you're looking for more info about that. If you're a technical writer and want to keep on top of the latest trends in the field, be sure to subscribe to email updates below. You can also learn more about me or contact me. Finally, note that the opinions I express on my blog are my own points of view, not that of my employer.











Please enable JavaScript to load the comments.



















 About idratherbewriting.com
Technical writing blog and API documentation course by Tom Johnson. 


Links

 Blog
API doc course
Contact



Tom on social media

 WTD Slack
 Twitter
 Linkedin



GitHub

GitHub repo
Log an issue
Closed issues








© 2023 Tom Johnson










"
Satya Nadella Says Copilot Will Be as Significant as the PC,"CoPilot, according to Satya Nadella, is set to be as significant as the PC, revolutionizing our tech interactions and defining the future.",03-10-23,https://jdmeier.com/satya-nadella-on-copilot/,https://jdmeier.com/wp-content/uploads/2023/09/Satya-Nadella-6.png, Microsoft Copilot,"





Satya Nadella Says Copilot Will Be as Significant as the PC | JD Meier



























































 Skip to main content Skip to after header navigation Skip to site footerJD MeierI help leaders change the world!MenuHeader SearchSearch siteSubmit searchABOUT
ARTICLES
BOOKS
COURSES
COACHING
RESOURCES
CONTACT
searchSearch siteSubmit search
Satya Nadella Says Copilot Will Be as Significant as the PC by JD Meier
“Alan Kay quips, ‘The best way to predict the future is to invent it.’” — Satya Nadella
Copilot set the stage for a new category of computing and a new wave of innovation.
This is a big deal.
But what I want to focus on is the power of a visionary leader to set out on bold ambitions and bring ideas to life.
In order to fully appreciate this, you have to go back in time to the future of Microsoft that Satya Nadella outlined several years ago.
I think this is a really good example of how a narrative memo can outline a North Star for the future that guides everyone on a more meaningful mission as they innovate and achieve big, bold dreams.
If you want to be a better leader, Satya’s example from ambition to fruition is a great example to remind you of the power of memos to change the world.
How Bold Ambitions Can Come to Fruition
I want to first take you back to 2015 when Satya’s email that outlined the future of Microsoft.
Satya outlined the strategy in terms of 3 bold ambitions:

Reinvent productivity and business processes
Build the intelligent cloud platform
Create more personal computing

You’ve already seen the intelligent cloud platform come to life, as well as improvement to productivity and personal computing.
But I think Copilot is really the piece of the puzzle that brings these ambitions to life in a serious, significant, and meaningful way for everyone.
What is Copilot?
Think of Copilot as having your very own ChatGPT seamlessly integrated into all your Microsoft applications – Windows, Edge, Excel, and PowerPoint.
In fact, it’s essentially Chat-GPT, powered by OpenAI, but with a unique twist – it’s context-aware and fully capable of interacting with your data and the software running on your PC.
While there’s more to it under the hood, this captures the essence of its capabilities.
Copilot will Usher in a New Era of Computing
Copilot represents the inflection point of a new wave of computing.
Here’s how Satya put it:
“We believe Copilot will fundamentally transform our relationship with technology and usher in the new era of personal computing,” — Satya Nadella
This statement by Satya Nadella, the CEO of Microsoft, means that he and Microsoft believe Copilot will bring about a significant shift in the way people interact with technology and use personal computing devices.
They see Copilot as a game-changer that will revolutionize how individuals work with computers, making the experience more intuitive, efficient, and user-friendly.
It implies that Copilot has the potential to redefine and enhance the overall user experience, marking a new era in personal computing.
Copilot is New Category of Computing
According to Satya, Copilot is essentially a new category of computing.
“This is as significant as the PC was to the ’80s, the Web in the ’90s, mobile in the 2000s, cloud in the 2010s.  Just like you boot up an operating system to access applications or use a browser to navigate websites, you will involve a Copilot to do all these activities and more.” — Satya Nadella
Satya Nadella is emphasizing the profound impact and transformative nature of Copilot.
He suggests that Copilot’s significance is on par with the major technological shifts of the past decades, such as the personal computer (PC) in the ’80s, the World Wide Web in the ’90s, the rise of mobile technology in the 2000s, and the emergence of cloud computing in the 2010s.
By comparing Copilot to these historical milestones, Nadella suggests that Copilot will become an integral part of how people interact with technology.
In the future, just as we currently use operating systems to access applications or browsers to navigate websites, we will engage with Copilot to perform a wide range of activities, making it a central component of our digital experiences.
This statement underscores the belief that Copilot will revolutionize the way we interact with and leverage technology in our daily lives.
From a Computer on Every Desktop to Empowering Every Person and Every Organization to Achieve More
The original mission of Microsoft was big.  But now the vision is bigger.
“You know I started in Microsoft when our mission was to put a PC in every home and every desk, and today we have a vision for a Copilot that can empower every person and every organization on the planet to achieve more.” — Satya Nadella
In this statement by Satya Nadella reflects on how Microsoft’s mission has evolved over the years.
When he started at Microsoft, the company’s goal was to make personal computers accessible to every home and desk.
Now, Microsoft’s vision has expanded to include Copilot, a technology that aims to empower not just individuals but also entire organizations worldwide.
The vision is to enable people and organizations across the globe to achieve more with the assistance of Copilot, illustrating Microsoft’s commitment to innovation and broadening its impact on the world.
More Knowledgable, More Productive, More Creative, More Connected
Copilot will help people realize their potential in unprecedented ways.
“We believe it has the potential to help you be more knowledgeable, more productive, more creative, more connected to the people and things around you.” — Satya Nadella
In this statement by Satya Nadella, Microsoft believes that Copilot has the potential to enhance various aspects of a user’s life.
It can make users more knowledgeable by providing information and insights, more productive by assisting with tasks, more creative by offering creative suggestions, and more connected by facilitating interactions with people and the digital world.
Essentially, Copilot is seen as a tool that can improve overall personal and professional capabilities, contributing to a richer and more efficient daily life.
A New Wave of Computing for Everyone
Satya Nadella’s visionary perspective on Copilot reveals the profound potential of this innovative technology.
With aspirations to empower individuals and organizations worldwide, Copilot is set to usher in a new era of personal computing.
By harnessing the capabilities of AI and integrating them seamlessly into our digital experiences, it promises to enhance our knowledge, productivity, creativity, and connectivity.
Nadella’s comparison of Copilot’s significance to past technological revolutions underscores its transformative potential, making it a key player in shaping the future of technology.
You Might Also Like
How Satya Nadella Helped Microsoft Rediscover Its Soul
How Satya Nadella Outlined the Future of Microsoft
How Satya Nadella Transformed Microsoft
Microsoft’s Recipe for Success
Satya Nadella on How Success is a Mental Game
Satya Nadella on Live and Work a Meaningful Life
Satya Nadella on the Key to Longevity
Satya Nadella Quotes
 
Category: AI, Leadership
About JD Meier

I help leaders change the world.


Previous Post:Microsoft’s Recipe for Success: A Growth Mindset
Next Post:What is Servant Leadership?
Reader InteractionsComments




Kaycee R 
October 3, 2023 at 7:21 pm 

Copilot is one word all lower case. This article sometimes refers to it as CoPilot. Full transparency, I’m a Microsoft employee.

Reply






JD Meier 
October 3, 2023 at 10:31 pm 

Fixed, thank you!  I guess too many years of camel case, lol.

Reply




 
Leave a Reply Cancel reply
Your email address will not be published. Required fields are marked *Comment * Name * 
Email * 
Website 












 

 
SidebarAbout Me

I am J.D. Meier. Microsoft 25 years. I help leaders change the world.
Learn more...

Popular Articles
10 Things Great Managers Do
10 Top Business Trends in 2023
40 Hour Work Week at Microsoft
Best Digital Transformation Books

How To Become an Innovator
How To Drive Digital Transformation
How To Lead High-Performance Teams
Innovation Explained
Satya Nadella Quotes
View More...



Become a better leader, innovate better, and achieve greater impact!
I help leaders change the world!  As part of your journey, learn how to realize your potential in business and in life through the power of high performance, innovation, and strategy. 
Leadership. Innovation. Entrepreneurship.
At the heart of high performance is a culture of continuous learning and growth, pushing us to be more creative than we thought possible. Innovation is the lifeblood of our digital era, a reflection of our commitment to harness technology to redefine boundaries. And strategy is our compass, a thoughtful alignment of our focus and resources.
Better Innovation, Better Results!
Innovation propels us forward, turning once-impossible dreams into tangible realities. It drives economic growth, fosters new ways of thinking, and solves complex problems that stand in the way of progress. Through innovation, we continuously redefine the boundaries of human potential and create a brighter future.



Topics

Innovation
Leadership
Entrepreneurship
High Performance
Strategy
Digital Transformation
Sustainability
All Topics



Resources

Frameworks
Trends
All Resources





Copyright © 2023 · JD Meier · All Rights Reserved















"
Meta is using your public Facebook and Instagram posts to train its AI,"<table><tr><td>Categories: News
Categories: Personal
Categories: Privacy
Tags: Meta

Tags: Facebook

Tags: Instagram

Tags: X

Tags: xAI

Tags: copyright

Tags: tweets

Social media companies are showing their hand about scraping user data to feed i…",03-10-23,https://www.malwarebytes.com/blog/news/2023/10/meta-is-using-your-public-facebook-and-instagram-posts-to-train-its-ai,https://www.malwarebytes.com/blog/news/2023/10/asset_upload_file75174_283988.png, XAI,"


Meta is using your public Facebook and Instagram posts to train its AI
































































































                 
                 
 
 




Personal



Personal


Products
Malwarebytes Premium >
Malwarebytes Privacy VPN >
Malwarebytes Premium + Privacy VPN >
Malwarebytes Browser Guard >
Malwarebytes for Teams/small offices >
AdwCleaner for Windows >
 
Have a current computer infection?
Clean your device now  
 






Solutions
Free antivirus >
Free virus scan & removal >
Windows antivirus >
Mac antivirus >
Android antivirus >
iOS security >
Chromebook antivirus >
 
See personal pricing 
 
Manage your subscription 
 
Visit our support page 









Business



Business


Solutions
By Company Size
Small Businesses
 1-99 Employees 
Mid-size Businesses
 100-999 Employees
Large Enterprise
 1000+ Employees
By Industry
Education
Finance
Healthcare
Government






Products
Cloud-based Security Management
Endpoint Protection
Endpoint Protection for Servers
Endpoint Detection & Response
Endpoint Detection & Response for Servers
Incident Response
Nebula Platform Architecture
Mobile Security
Cloud-based Security Modules
DNS Filtering
Vulnerability & Patch Management
Remediation Connector Solution
Application Block
Security Services
Managed Detection and Response 
Cloud Storage Scanning Service 
Malware Removal Service
Next-gen Antivirus for Small Business
For Teams






Get Started


Find the right solution for your business
 See business pricing  



Don't know where to start?
 Help me choose a product  



See what Malwarebytes can do for you
 Get a free trial  



Our sales team is ready to help. Call us now
+1-800-520-2796









Pricing


Partners





Partners



  Explore Partnerships 



Partner Solutions
Resellers
Managed Service Providers
Computer Repair
Technology Partners
Affiliate Partners
Contact Us 
 




Partner Success Story


Marek Drummond
Managing Director at Optimus Systems
""Thanks to the Malwarebytes MSP program, we have this high-quality product in our stack. It’s a great addition, and I have confidence that customers’ systems are protected.""

See full story 
 





Resources



Resources


Learn About Cybersecurity
Antivirus
Malware
Ransomware
Malwarebytes Labs – Blog
Glossary
Threat Center






Business Resources
Reviews
Analyst Reports
Case Studies
Press & News






Reports

The State of Malware 2023 Report
See Report 







Support



Support


Technical Support
Personal Support
Business Support
Premium Services
Forums
Vulnerability Disclosure
Report a False Positive






  Product Videos 







Featured Content
  
Activate Malwarebytes Privacy on Windows device.
See Content 







FREE DOWNLOAD




Contact Us



Contact Us

Personal Support
Business Support
Talk to Sales
Contact Press
Partner Programs
Submit Vulnerability






Company



Company

About Malwarebytes
Careers
News & Press






Sign In



Sign In

MyAccount: manage your personal/Teams subscription >
Cloud Console: manage your cloud business products >
Partner Portal: management for Resellers and MSPs >































SUBSCRIBE




































 

News
                             |                                                         Personal
                             |                                                         Privacy

Meta is using your public Facebook and Instagram posts to train its AI

                            Posted: October 3, 2023
                                                        by Pieter Arntz

Social media companies are showing their hand about scraping user data to feed into their AI and large language models.

Post anything publicly on Facebook and Instagram? Meta has likely been using those posts to train its AI, according to the company's top policy executive.
In an interview with Reuters, Meta President of Global Affairs Nick Clegg said the company used the public posts to train the LLM (large language model) that feeds into its new Meta AI virtual assistant.

Large Language Models (LLMs) are huge deep-neural-networks which are trained on the input of billions of pages of written material in a particular language, such as books, articles, and websites. So, in in the ongoing race between tech giants to create the best LLM it's hardly surprising that they're looking at social media as a giant source of data.
Clegg said that Meta excluded private posts shared only with family and friends, as well as private chats on its messaging services:
""We've tried to exclude datasets that have a heavy preponderance of personal information and the ""vast majority"" of the data used by Meta for training was publicly available.”

He also said they decided against using LinkedIn content for privacy reasons.
In separate news, X (formerly Twitter) updated its Terms of Service to let it use tweets for AI training. In July 2023, Elon Musk announced the launch of xAI to “understand the true nature of the universe.” In more realistic terms it looks like xAI will set out to compete with companies like OpenAI, Google, and Microsoft, which are behind leading chatbots like ChatGPT, Bard, and others.
Given that Musk threatened to sue Microsoft for using Twitter data for training, it may come as a surprise to some that the policy change states:
“We may use the information we collect and publicly available information to help train our machine learning or artificial intelligence models for the purposes outlined in this policy.”
Musk has already said that xAI will use public tweets for AI model training and in a tweet responding to comments about the policy change, Musk clarified that the plan is to use “just public data, not DMs or anything private.”
So, that seems to be the consensus about what is acceptable to scrape of your social media presence. If others can see it, it’s public knowledge and the tech giants are of the opinion they can use it to train their AI.
There is a world of difference to me, between data being publicly available and then feeding them into an AI that can combine it with information from other sources at a speed faster than any human is capable of.
Another undesirable side-effect of these developments is that the social media giants are relegating the responsibility for scraping copyright protected media and using them unwittingly. Asked whether Meta had taken any such steps to avoid the reproduction of copyrighted imagery, a Meta spokesperson pointed to new terms of service barring users from generating content that violates privacy and intellectual property rights. In other words, it's not our problem but the user's.
What to do
Now more than ever you should assume that anything you post on social media is up for grabs for anyone. An extra point of attention is the use of copyrighted material in your posts. The social media companies will not think twice to use it, and hold you responsible for the fact that they copied them from you without asking.
And please don’t believe all the posts, especially rampant on Facebook, that you can protect your content by copying and pasting some 10 year old post that has done at least twenty laps on the platform. You can't.
Be warned that based on the AI-assigned definitions in the updated terms by X, your access to certain content might be limited, or even cut off. As a consequence, you may find it harder to reach your intended audience. Maybe it really is time to switch to a different platform.

We don’t just report on threats—we remove them
Cybersecurity risks should never spread beyond a headline. Keep threats off your devices by downloading Malwarebytes today. 

SHARE THIS ARTICLE


















COMMENTS





RELATED ARTICLES







ABOUT THE AUTHOR




Pieter Arntz






Malware Intelligence Researcher

Was a Microsoft MVP in consumer security for 12 years running. Can speak four languages. Smells of rich mahogany and leather-bound books.




















            Contributors







            Threat Center







            Podcast







            Glossary







            Scams









 










Cyberprotection for every one.









 


Cybersecurity info you can't do without
Want to stay informed on the latest news in cybersecurity? Sign up for our newsletter and learn how to protect your computer from threats. 












Cyberprotection for every one.



For Personal
Windows Antivirus
Mac Antivirus
Android Antivirus
Free Antivirus
VPN App (All Devices)
Malwarebytes for iOS
See all


Company
About Us
Contact Us
Careers
News and Press
Blog
Scholarship
Forums
 


FOR BUSINESS
Small Businesses
Mid-size Businesses
Large Enterprise
Endpoint Protection
Endpoint Detection & Response
Managed Detection and Response (MDR)


FOR PARTNERS
Managed Service Provider (MSP) Program
Resellers

MY ACCOUNT
Sign In

 


SOLUTIONS
Rootkit Scanner
Trojan Scanner
Virus Scanner
Spyware Scanner
Password Generator
Anti Ransomware Protection



ADDRESS
3979 Freedom Circle12th Floor Santa Clara, CA 95054


ADDRESS
One Albert Quay2nd Floor Cork T12 X8N6 Ireland

 


LEARN
Malware
Hacking
Phishing
Ransomware
Computer Virus
Antivirus
What is VPN?


COMPANY
About Us
Contact Us
Careers
News and Press
Blog
Scholarship
Forums


MY ACCOUNT
Sign In



ADDRESS
3979 Freedom Circle, 12th Floor Santa Clara, CA 95054


ADDRESS
One Albert Quay, 2nd Floor Cork T12 X8N6 Ireland

 






 







                               English





Legal


Privacy


Accessibility


Vulnerability Disclosure


Terms of Service



© 2023 All Rights Reserved










Select your language


























New


 







Buy Online











Partner Icon




















Warning Icon














"
Windows 11 KB5030310 update and Copilot is causing issues with Wallpaper Engine,"Last week Microsoft finally released the KB5030310, aka the Moment 4 update to the users. While it comes with a host of new features, it looks like the Moment 4 update is breaking Wallpaper Engine. Read more...",02-10-23,https://www.neowin.net/news/windows-11-kb5030310-update-and-copilot-is-causing-issues-with-wallpaper-engine/,https://cdn.neowin.com/news/images/uploaded/2023/08/1690966571_windows_11_logo_story.jpg, Microsoft Copilot,"





























Windows 11 KB5030310 update and Copilot is causing issues with Wallpaper Engine - Neowin
 
















































Neowin










Login
Sign up











Facebook



Twitter

Follow @neowinfeed

YouTube



Mastodon
RSS










Log in


Sign up


News
News


Software
Microsoft
Gaming
Guides
Closer Look
Windows 10
Windows 11





Latest
Microsoft
Google
Apple
Software












The MOBA game Gigantic, which shut down in 2018, is getting a temporary comeback


25 minutes ago











Edge Dev 119.0.2132 is out with new features and bug fixes


41 minutes ago











Apple Arcade getting four new games including NBA 2K24 Arcade Edition


1 hour ago











Surface Laptop Studio 2 and Laptop Go 3 get day-one patches and improvements


1 hour ago




View all recent news











Edge Dev 119.0.2132 is out with new features and bug fixes


41 minutes ago











Surface Laptop Studio 2 and Laptop Go 3 get day-one patches and improvements


1 hour ago











Microsoft 365 Insiders can try out putting in Planner board links in Microsoft Loop


4 hours ago











PowerToys 0.74.1 Patch fixes issues with FancyZones, SVG Preview, Quick Accent, and more


11 hours ago




View all Microsoft news











How to watch Made By Google 2023: Pixel 8 and 8 Pro launch event


8 hours ago











Google Chrome 117.0.5938.150 (offline installer)


12 hours ago











Microsoft was willing to lose billions and ditch Bing name to secure Apple search deal


Oct 3, 2023











Microsoft says it spent $100 Billion on Bing and is stopping Google from having a monopoly


Oct 2, 2023




View all Google news











Apple Arcade getting four new games including NBA 2K24 Arcade Edition


1 hour ago











Microsoft was willing to lose billions and ditch Bing name to secure Apple search deal


Oct 3, 2023











Apple Watch Ultra 2's display is reportedly too difficult to read in low light


Oct 2, 2023











Apple has been building powerful search software, could be a bargaining chip against Google


Oct 2, 2023




View all Apple news











Glow 1.88 [Update]


3 hours ago











ExplorerPatcher 22621.2361.58.2


5 hours ago











Google Chrome 117.0.5938.150 (offline installer)


12 hours ago











Snagit 2024.0


13 hours ago




View all software news






Features

Reviews
Top 10
Guides
Unboxings
Trending
Editorials




Reviews
Top 10
Guides
Specs Appeal
Trending
Editorials












TerraMaster F2-212 review: Home media AV1 streaming and cloud backup on the cheap


Oct 1, 2023











GEEKOM Mini IT13 review: the first Mini PC with 13th gen Intel Core i9 inside


Sep 24, 2023











Review: The GEEKOM PM16 is no frills FullHD 16"" portable monitor for under $150


Sep 16, 2023











Epomaker RT100 keyboard review: A retro looking keyboard with modern and unique features


Sep 10, 2023




View all reviews











Top 10 apps to fix Windows 11's inconveniences


Apr 11, 2023











Top 10 most requested features Microsoft has already brought to Windows 11


Mar 4, 2023











Top 10 features and changes Windows 11 users want for File Explorer


Feb 5, 2023











Here are the top 10 improvements Windows 11 users want for the Settings app


Jan 29, 2023





View all Top 10s












How to turn off or remove Windows Copilot on Windows 11


Sep 30, 2023











Mastering Microsoft Outlook: 20 Expert Tips & Tricks Guide Download


Sep 25, 2023











How to install Windows 11 Moment 4 Update?


Sep 24, 2023











The Ultimate ChatGPT Prompts Guide (lifetime subscription) now 74% off 


Sep 23, 2023




View all guides











Specs Appeal: Comparing the Surface Laptop Go 3 with Laptop Go 2 and Laptop Go


Sep 23, 2023











Specs Appeal: Here is how the Surface Laptop Studio 2 compares to Surface Laptop Studio


Sep 21, 2023











Specs Appeal: What is the difference between iPhone 15, 15 Plus, 15 Pro, and 15 Pro Max?


Sep 13, 2023











Specs Appeal: Comparing iPhone 15, iPhone 14, and iPhone 13


Sep 13, 2023




View all Specs Appeal











Windows 11 concept becomes almost-reality as Microsoft adds SkiFree-like game to setup OOBE


14 hours ago











Microsoft OneDrive 3.0 revealed with new design, new sharing features, Copilot AI, and more


14 hours ago











VeraCrypt gets bootloader, memory encryption, UAC, Quick Format upgrades on Windows 11/10


Oct 3, 2023











You can no longer activate new Windows 11 builds with Windows 7 or 8 keys


Sep 28, 2023




View all trending news











I wanted the ""Wow"" factor for the Apple Vision Pro reveal, but all I got was a ""Why?""


Jun 6, 2023











Navigating Microsoft's AI Frontier: Unveiling tech giant's path with caution and critique


May 28, 2023











Editorial: It's right that big tech leans up with layoffs, focusing on profitable activities


May 27, 2023











NVIDIA shares recently hit $380 each, but is the price fair?


May 26, 2023




View all editorials






Forums


Store



Recent
Highlights
Interests
On a Budget












Price Dropped: Microsoft Office Pro 2021 + Windows 11 Pro now 88% off


15 hours ago











Save 80% on this Price Dropped lifetime subscription to AdGuard Family Plan


Oct 2, 2023











Save 88% on this complete Excel, VBA, and Data Science Certification Training Bundle


Oct 1, 2023











Save 75% on a Ultimate Lifetime Bundle of StackSkills + Infosec4TC + Stone River


Sep 30, 2023




View all recent deals











Best Sellers











Pay What You Want











Gear + Gadgets











Software Bundles




View all Neowin Deals











For Developers











Productivity











Accessories











E-Learning




View all Neowin Deals











Under $20











Freebies











Giveaways




View all Neowin Deals






More

Subscribe
Store
Chat on IRC
Send News Tip
Write for Neowin
About Us
Advertising











Software


Gaming


Microsoft


Deals


Windows vNext


Windows 10


Windows 11


Insiders


Server


Write for us


                        Send news tip
                    





















                            Windows 11 KB5030310 update and Copilot is causing issues with Wallpaper Engine                            



Mehrotra A

Neowin
                ·
    

    Oct 2, 2023 13:42 EDT
    

with 14 comments




Wallpaper Engine is one of the most popular third-party apps offering millions of wallpers to users. However, it looks like the recent Windows 11 update may have broken the app for users. In case you missed it, last week Microsoft released the Moment 4 update for Windows 11 which brought new features and Windows Copilot, a generative Artificial Intelligence (AI) assistant powered by Bing AI.
Unfortuately, Windows Copilot may be the culprit when it comes to performance issues with Wallpaper Engine. Users on Reddit and the Steam community have mentioned that the new update is causing a conflict with the app resulting in various issues and crashes. On a separate thread on the Steam community, the dev team acknowledged the issue and noted that the best solution for the users is to get off Windows Insider Preview and disable HDR.
Back in July when Microsoft was testing the Moment 4 update, the Wallpaper Engine team had confirmed that they had a conversation around the update and the issues reported by Windows Insiders.





 
After a discussion with Microsoft, they have removed the HDR wallpaper feature for now and they will overhaul the underlying system so that compatibility with wallpaper apps like Wallpaper Engine will be kept in the future.

The team also noted that due to the large number of complaints, they are unable to reply to everyone but have suggested getting off the Insider Preview as Microsoft is making extreme changes to Windows Desktop and it is not feasible for the team to provide solutions.

We currently cannot fix issues for you because we extensively talked to Microsoft and they are making extreme changes to the desktop experience right now and partially rolling back some recent changes. It's just not realistically possible to provide support for this under the current circumstances though we are working with Microsoft for a long-term solution before these updates go live to stable versions of Windows. We will look at their changes in due time. If you want a stable Windows experience, please opt out of the Windows Insider's program. It sounds harsh but that is the only honest suggestion we can make.

Unfortunately, we are seeing same reports from users on the Feedback Hub as well. Personally, I had to reinstall Wallpaper Engine and disable Windows Copilot after the Moment 4 update on my system. It does not look like Microsoft addressed the issue completely before releasing the Moment 4 update to users.
Thankfully, you can disable Windows Copilot if it is causing issues or if you are not a fan of the new AI assistant. If you are in the EU, then consider yourself lucky as a recent law has prevented Microsoft from rolling out Copilot to users in the EU. However, you may not be as fortunate if you have an AMD GPU as the new update is causing all kinds of driver issues for AMD users.


Tags


Microsoft


Windows


Windows 11


Windows copilot


Windows copilot preview


Wallpaper engine


Steam






Like
Tweet
Share


Report a problem with article

Follow @NeowinFeed









Next Article

                Business Connectivity Services (BCS) in Microsoft 365 will be shut down on Sept. 30, 2024                












Previous Article

                Spotify could be working on an AI-powered feature to create unique playlists                








			Related Stories
		










How to turn off or remove Windows Copilot on Windows 11
                                            



Mehrotra A
                                                ·
                    
Sep 30, 2023

with
68
                            comment
                                s
                                                            













Windows Copilot is not available the EU due to Digital Markets Act but there's a workaround
                                            



Mehrotra A
                                                ·
                    
Sep 27, 2023

with
19
                            comment
                                s
                                                            













Hands-on with Windows Copilot: A buggy mess that will (hopefully) get better with time
                                            



Mehrotra A
                                                ·
                    
Jul 2, 2023

with
23
                            comment
                                s
                                                            













Want to try Windows Copilot now? Here's how you can enable it now on Windows 11
                                            



Mehrotra A
                                                ·
                    
Jun 30, 2023

with
2
                            comment
                                s
                                                            





















Subscribe to our Newsletter

















Community Activity

Refresh




O&O DriveLED uninstall; spyware?

                            in
                            Software Discussion & Support



Thermalright CPU Coolers

                            in
                            Hardware Hangout



What's The Smallest PC I Can Buy/Build With A Dedicated GPU Inside?

                            in
                            PC Gaming



In need of comfortable shoes

                            in
                            General Discussion



Neowin's 2023 Desktops Thread

                            in
                            General Discussion








Software Stories










Glow 1.88 [Update]









ExplorerPatcher 22621.2361.58.2









Google Chrome 117.0.5938.150 (offline installer)









Snagit 2024.0






Trending Stories









Windows 11 concept becomes almost-reality as Microsoft adds SkiFree-like game to setup OOBE









Microsoft OneDrive 3.0 revealed with new design, new sharing features, Copilot AI, and more









VeraCrypt gets bootloader, memory encryption, UAC, Quick Format upgrades on Windows 11/10









You can no longer activate new Windows 11 builds with Windows 7 or 8 keys





















Join the conversation!
Login or Sign Up to read and post a comment.


14 Comments - Add comment




Sort by oldest first (thread view)
Sort by newest first (thread view)
Sort by oldest first (linear view)
Sort by newest first (linear view)






















Report Comment
Close


Please enter your reason for reporting this comment.






















review


                                GEEKOM Mini IT13: the first Mini PC with 13th gen Intel Core i9 inside
                                

                                geekom mini it13
                                












Dev Channel


                                Windows 11 build 23545 fixes a number of File Explorer bugs and more
                                

                                windows 11 insider preview
                                












Canary Channel


                                Windows 11 Build 25951 adds some new SMB features
                                

                                windows 11 insider preview promo
                                












throwback


                                A quick look back at the reveal of the first Android smartphone 15 years ago
                                

                                htc dream
                                












compare


                                Microsoft Surface news & Specs Appeal
                                

                                surface laptop go 3
                                












compare


                                iPhone 15 coverage and Specs Appeal
                                

                                iphone 15
                                












guide


                                Here is how you can get the Windows 11 Moment 4 Update right now
                                

                                windows 11 moment 4
                                












Review


                                The GEEKOM PM16 is no frills FullHD 16"" portable monitor for under $150
                                

                                geekom pm16
                                












This Week in Rocket Launches #132


                                Amazon's Project Kuiper internet satellites launching this week
                                

                                twirl
                                












Beta Channel


                                Chat becomes Microsoft Teams Free with build 22631.2338 (KB5030305)
                                

                                windows 11 insider preview promo
                                












review


                        The GEEKOM PM16 is a no frills FullHD 16"" portable monitor for under $150
                        

                        geekom pm16
                        










review


                        Epomaker RT100 embodies a retro look with modern and unique features
                        

                        epomaker
                        












                        Here is everything new in Windows 11 23H2, the next big feature update
                        

                        windows 11 23h2
                        










review


                        Review of the Beelink SER6 Max metal encased AMD Ryzen 7 7735HS power
                        

                        beelink ser6 max
                        






















Company


Contact Us


About Us


Write for Neowin


Advertising




Community


Forums


Subscribe


Chat on IRC


Neowin Deals




Social

Facebook
Twitter
YouTube
Mastodon

RSS




Partners


Star Control


Fences


Brad Wardell


Store













DMCA Policy ·
Terms of Use ·
Privacy Statement


© Since 2000 Neowin LLC.
                                    All trademarks mentioned are the property of their respective owners.
                                


Top of Page











Login
Close









Username or email:



Password






                                Remember me
                                





Sign In

                        Sign in with Facebook
                    

                        Sign in with Twitter
                    

                        Sign in with Google
                    

                        Sign in with Microsoft
                    








Loading











"
Rising Interest in AI Insurance Amid Growing Concerns,"As the world of generative artificial intelligence continues to advance, businesses are increasingly aware of the various risks associated with AI projects. These risks range from cybersecurity issues to potential copyright infringement, inaccurate or biased …",02-10-23,https://www.cryptopolitan.com/rising-interest-in-ai-insurance/,https://img.cryptopolitan.com/wp-content/uploads/2023/10/AI-insurance.jpeg, Microsoft Copilot,"  Rising Interest in AI Insurance Amid Growing Concerns – Cryptopolitan           
Skip to content



















































Converter 

NewsBitcoinBinanceRippleEthereumCardanoDogecoinDeFiNFTETFsPrice PredictionsBitcoinEthereumCardanoXRPDogecoinLitecoinBitcoin CashChainlinkEthereum ClassicVeChainTronEOSCROAlgorandZcashHolochainZilliqaDigibyteDentKINMATICWRXSHIBUNIDOTBNBSUSHIAAVECAKEENJWINKSolanaPIVXVoyagerAvalancheDentacoinArdorLCXVIBETRACSTEEMXYOBAXTRBCROREQLoopringDecentralandCosmosLearnCrypto 101Crypto WalletsCrypto InvestingCrypto MiningRegulationResearchScamsTechnologyBlockchain GamingMetaverseStoriesWeb3 Masterminds



































NewsBitcoinBinanceRippleEthereumCardanoDogecoinDeFiNFTETFsPrice PredictionsBitcoinEthereumCardanoXRPDogecoinLitecoinBitcoin CashChainlinkEthereum ClassicVeChainTronEOSCROAlgorandZcashHolochainZilliqaDigibyteDentKINMATICWRXSHIBUNIDOTBNBSUSHIAAVECAKEENJWINKSolanaPIVXVoyagerAvalancheDentacoinArdorLCXVIBETRACSTEEMXYOBAXTRBCROREQLoopringDecentralandCosmosLearnCrypto 101Crypto WalletsCrypto InvestingCrypto MiningRegulationResearchScamsTechnologyBlockchain GamingMetaverseStoriesWeb3 MastermindsFollow us











Search for:


Home » AI » Trending News
Rising Interest in AI Insurance Amid Growing Concerns
October 2, 2023 by Derrick Clinton
3 mins read
  
Content 
1.
AI Insurance: A New Frontier
 
2.
Pioneering efforts in AI insurance
 
3.
Vendor initiatives and legal safeguards
 
4.
Learning from cyber insurance
TLDRAI insurance addresses risks in generative AI adoption.Major carriers may offer specialized coverage as demand grows.AI insurance parallels lessons learned from cyber insurance evolution.As the world of generative artificial intelligence continues to advance, businesses are increasingly aware of the various risks associated with AI projects. These risks range from cybersecurity issues to potential copyright infringement, inaccurate or biased outputs, misinformation, and the inadvertent leaking of proprietary data. For business technology executives, these concerns can keep them up at night. However, amidst these apprehensions, insurance companies are recognizing a unique opportunity.AI Insurance: A New FrontierDrawing inspiration from the growth of cybersecurity insurance, which saw a surge in demand following major data breaches in recent years, insurance providers are now venturing into the realm of AI insurance. They are offering financial protection against the failure of AI models. This development is particularly welcomed by corporate technology leaders who see these policies as a means to address risk-management concerns voiced by board members, chief executives, and legal departments.Niranjan Ramsunder, Chief Technology Officer and Head of Data Services at UST, a digital technology and information-technology services firm, highlights the emerging interest in AI insurance. “You will find more and more people starting to ask, ‘Who takes the risk? How do you fund it? And can you take care of some of the risk for us?'” he says. These questions are at the forefront as businesses grapple with the evolving landscape of generative AI.While it’s still early days, analysts suggest there is a palpable appetite for AI insurance, especially for coverage related to financial losses stemming from AI and generative AI technologies. Even existing liability or cybersecurity policies could soon be tailored to accommodate generative AI. Although there isn’t a clear-cut example of generative AI causing data leakage leading to damages, the potential for such scenarios is enough to spur interest in insurance options.Avivah Litan, a Gartner analyst focusing on AI trust, risk, and security, predicts, “I would bet that over fifty percent of large enterprises would buy some of these insurance policies if they come out, and they make sense.”  Pioneering efforts in AI insuranceMunich Re, a German reinsurer, ventured into the AI insurance space in 2018 by offering coverage for companies selling AI services. Michael Berger, head of Munich Re’s Insure AI product, explains that they also insure enterprises developing their own AI models by covering financial losses resulting from mistakes that a human wouldn’t have made. This approach provides a safety net for businesses navigating the uncharted waters of AI development.Another player in the AI insurance arena is Armilla Assurance, a Toronto-based startup that launched this year. They offer a product warranty, backed by reinsurers including Swiss Re and Chaucer, guaranteeing that AI models will perform as promised by their sellers. This assurance is a step toward instilling confidence in businesses looking to integrate generative AI into their operations.Vendor initiatives and legal safeguardsRecognizing the concerns businesses have about incorporating generative AI into their operations, tech giants like Microsoft, IBM, and Adobe are taking steps to mitigate risks. IBM, for instance, recently announced that its standard contractual intellectual property protections will extend to the generative AI models it develops. Similarly, Adobe allows businesses to purchase IP indemnification to protect against potential copyright issues related to generative-AI-created content on its Firefly platform.Microsoft, in a noteworthy move, committed to defending and covering the legal costs of lawsuits arising from a customer’s use of its generative-AI-based Copilot tools, provided the customers use the built-in guardrails to filter out copyrighted content. This commitment has been a game-changer, as it has encouraged technical and product teams to adopt GitHub’s Copilot generative AI coding assistant, knowing that Microsoft is financially committed to supporting its customers in legal matters.Learning from cyber insuranceThe evolution of cyber insurance offers valuable lessons for the emerging AI insurance sector. Cyber insurers have increased scrutiny of policyholders’ security arrangements, resulting in more expensive policies and coverage denials, particularly during the pandemic. With a rise in costly cyberattacks, insurers have also raised premiums and reduced coverage. AI insurance policies could follow a similar trajectory as underwriting methods adapt and insurers grapple with the complexities of AI-related claims.However, AI insurance faces unique challenges. The absence of historical data on AI model performance and usage in business makes it difficult for insurers to assess risk accurately. Additionally, generative AI models are evolving rapidly, requiring dynamic risk-assessment methods.Disclaimer. The information provided is not trading advice. Cryptopolitan.com holds no liability for any investments made based on the information provided on this page. We strongly recommend independent research and/or consultation with a qualified professional before making any investment decisions.Share link:




























Written by Derrick Clinton
Derrick is a freelance writer with an interest in blockchain and cryptocurrency. He works mostly on crypto projects' problems and solutions, offering a market outlook for investments. He applies his analytical talents to theses.  
Categories Trending News, AIFive Vital Compliance Tips for AI-Driven Marketing Data PrivacyCardano Price Prediction 2023-2032: Is ADA a good investment?Most readBitcoin Price Prediction 2023-2032: Will Bitcoin Bulls Rally?How Can You Rate Plasma vs Sidechains Based on Features and Applications?Dogelon Mars Price Prediction 2023-2032: Is ELON a Good Investment?A Decade of Spotting Fraud, Fighting Scams, and a Fitting Closer – The SBF/FTX CatastropheJordan Financial Expo & Award, where the past embraces the blockchain-based future  Related News
Show All




How AI Is Teaching Old Banners New Tricks: Enhancing Efficiency and Creativity in Digital Advertising            	
October 4, 20233 mins read




SoftBank CEO Masayoshi Sets Timeline for Artificial General Intelligence Revolution            	
October 4, 20232 mins read




Meta’s Reality Labs Division Plans Layoffs in Silicon Unit            	
October 4, 20233 mins read




Tech Industry Sees Layoffs in 2023 Amidst Ongoing Transformation            	
October 4, 20233 mins read













Cryptopolitan dailyDiscover our daily newsletter, empowering investors with market insights.
Subscribe



















Your gateaway into the world of Web3Top SectionNewsPrice predictionBitcoin newsRegulationResearchScamsTechnologyLearnAIGamingCompanyAboutContactEventsStoriesWrite for usApply for ...Advertise with usOur ProductsCurrency ConverterCrypto portoflio tracker
Social Block cme



















Your gateaway into the world of Web3
Copyright 2023 CryptopolitanPrivacy PolicyEditorial PolicyCookie PolicyComment PolicyTerms and conditionsCryptopolitan                             

"
On theCUBE Pod: Thoughts on Amazon investing in Anthropic and the FTC problem,"There was a lot of big news in the tech world this week, but one of the most significant involved Amazon.com Inc. announcing it would invest up to $4 billion in Anthropic, the San Francisco-based startup behind the Claude 2 large language model. Anthropic’s n…",02-10-23,https://siliconangle.com/2023/10/02/on-thecube-pod-thoughts-on-amazon-investing-in-anthropic-and-the-ftc-problem-thecubepod/,https://d15shllkswkct0.cloudfront.net/wp-content/blogs.dir/1/files/2023/10/DaveVellante_JohnFurrier_TheCubePodcastSept31.png, Azure Open AI,"


On theCUBE Pod: Thoughts on Amazon investing in Anthropic and the FTC problem - SiliconANGLE





























































































































[the voice of enterprise and emerging tech]



search


Sign In






menu






account_circle







search


Home
Cloud 

Cloud Native


AI
Security
Infra
Blockchain
Policy
Big Data
Apps
Emerging Tech
Iot
Women In Tech
Wikibon Research
Special Reports
Video Exclusives
CUBE SPECIAL FEATURES
RECENT CUBE EVENTS
 







































SHARE 







Coverage from SiliconANGLE's livestreaming video studiohelp_outline








UPDATED 11:32 EDT / OCTOBER 02 2023





 AI




	                    On theCUBE Pod: Thoughts on Amazon investing in Anthropic and the FTC problem					

 

VIDEO EXCLUSIVE					        	                        by 
Ryan Stevens





SHARE 



There was a lot of big news in the tech world this week, but one of the most significant involved Amazon.com Inc. announcing it would invest up to $4 billion in Anthropic, the San Francisco-based startup behind the Claude 2 large language model. Anthropic’s newest and most advanced model, Claude 2, is designed to compete with OpenAI’s GPT-4.
It was a huge week for Amazon, according to theCUBE industry analyst John Furrier (pictured, left). Anthropic is reportedly gearing up to develop a highly advanced foundational model, Claude Next.
“Anthropic gives them a major piece of the puzzle,” Furrier said, on the latest episode of theCUBE Podcast. “They’ve got the training and inference stuff with Anthropic. That’s going to give them an OpenAI alternative.”
The ongoing AI wars
The war over artificial intelligence continues, according to Furrier. There are also interesting subjects to focus on when one pulls out the data around this subject, according to theCUBE industry analyst Dave Vellante (right).
“The data is actually really interesting on what customers are doing. This is more enterprise focus, which is kind of the area that we focus on mostly,” Vellante said. “When you look at who’s using and plans to evaluate, Microsoft Azure and OpenAI are tops; 60% of the customers say they’re doing stuff or playing around with it.”
Second is Google LLC with Vertex AI, and third is Amazon in terms of who people plan to utilize or evaluate it once Amazon Bedrock becomes generally available, which has now happened. No. 2, maybe even tied for No. 1, is “other,” according to Vellante.
“I found that really interesting,” he said. “Others, we’re talking about Meta, Anthropic, Falcon, Cohere, Hugging Face, all these other alternatives. What that says to me is this thing is wide open.”
Others who popped up in the data included IBM Corp’s watsonx and Oracle Corp. The data suggests this is a wide-open field, and Amazon’s investment in Anthropic makes a big difference, Vellante noted.
“Amazon is right there, and developers — I mean, Amazon could be in a good position here if they don’t screw it up,” Vellante added.
Legal challenges loom
Despite the big purchase, Amazon is facing a legal challenge from the Federal Trade Commission. This week, the 17 state attorneys general sued Amazon for allegedly using anticompetitive business tactics in the e-commerce market. The move raised questions about how Amazon is hurting people, according to Furrier. It also further called into question how the FTC has been operating.
“People rise to the top, beat the competition, sometimes put them out of business. Is this the way we want to have people like [FTC Chair] Lina Khan, who are taking this vision of their view of the world?” Furrier said. “It just seems like her tactical execution, and why she’s doing these things, it’s the exact opposite of what we need to do to help our citizens and consumers.”
It feels as though the public-private partnerships in the United States are deteriorating, according to Vellante. Ray Dalio, founder of Bridgewater Associates, talked on this subject at the All-In Summit in September.
“He went back in history and looked at all the great powers and the ascendancy and decline of these great powers and their reserve currency,” Vellante said. “The guy did some amazing research. And, of course, I like him because he’s very concerned about debt.”
Dalio presented a number of factors that led to the rise and fall of nations, including education, technology, competitiveness, economic output and world trade. It all leads to the reserve currency, Vellante noted.
“The point is, that when you think about the public and private partnership, those are the factors where the investment should be,” he said. “And I feel like the U.S. government is attacking a lot of that innovation. We don’t have enough STEM students, right? It’s going to eventually impact technology. [JC2 Ventures’] John Chambers said this: There’s just no guarantee for the future. You’ve got to go earn it.”
Tesla Inc. CEO Elon Musk has also discussed how things get invented because people take chances and risks. Technology just doesn’t happen, Vellante noted.
“It takes real effort,” he said. “That’s where if a government is working against private industry; that’s going to be a real detriment to the success of a nation. And I don’t understand why many in our government don’t see this.”
Watch the full podcast below to find out why these industry pros were mentioned:
Lina Khan, chair of the Federal Trade Commission
Andy Jassy, president and CEO of Amazon
Jony Ive, former SVP of industrial design and CDO of Apple
Sam Altman, CEO of OpenAI
Mark Zuckerberg, CEO of Meta Platforms
Lex Fridman, research scientist at MIT
Linda Yaccarino, CEO of X
Paul Martino, founder of Bullpen Capital
Sal Khan, CEO of Khan Academy
Babe Ruth, legendary professional baseball player
Matt Baker, SVP of AI Strategy for Dell Technologies
Scott Johnston, CEO of Docker
Erik Bradley, chief strategist and director of research at ETR
Tara Murphy Dougherty, CEO of Govini
John Chambers, CEO of JC2 Ventures
Elon Musk, CEO of Tesla
Adam Selipsky, CEO of AWS
Yoel Roth, internet personality, a Knight Visiting Scholar at the University of Pennsylvania, a technology policy fellow at UC Berkeley, and a non-resident scholar at the Carnegie Endowment for International Peace
Clay Shirky, vice provost for AI and technology in education at NYU
Cory Doctorow, author, journalist and activist
Jeff Jarvis, professor, director Tow-Knight Center for Entrepreneurial Journalism at Craig Newmark Graduate School of Journalism at CUNY
Don’t miss out on the latest episodes of “theCUBE Pod.” Join us by subscribing to our RSS feed. You can also listen to us on Apple Podcasts or on Spotify. And for those who prefer to watch, check out our YouTube playlist.

Photo: SiliconANGLE

A message from John Furrier, co-founder of SiliconANGLE:
Your vote of support is important to us and it helps us keep the content FREE.
One-click below supports our mission to provide free, deep and relevant content.  
Join our community on YouTube
Join the community that includes more than 15,000 #CubeAlumni experts, including Amazon.com CEO Andy Jassy, Dell Technologies founder and CEO Michael Dell, Intel CEO Pat Gelsinger and many more luminaries and experts.


“TheCUBE is an important partner to the industry. You guys really are a part of our events and we really appreciate you coming and I know people appreciate the content you create as well” – Andy Jassy


THANK YOU
 





LATEST STORIESAfter 10 years of crypto scammers, there's still a rocky road aheadReport: Over half of phishing emails now use obfuscation tactics to avoid detectionEU telcos call for big tech to help finance internet infrastructure upgradesMitel closes deal to acquire Unify from AtosCrypto exchange Coinbase lands major regulatory approval in Singapore amid global expansionOn theCUBE Pod: Thoughts on Amazon investing in Anthropic and the FTC problemLATEST STORIESAfter 10 years of crypto scammers, there's still a rocky road aheadBLOCKCHAIN - BY DAVID STROM . 1 MIN AGOReport: Over half of phishing emails now use obfuscation tactics to avoid detectionSECURITY - BY MARIA DEUTSCHER . 1 HOUR AGOEU telcos call for big tech to help finance internet infrastructure upgradesPOLICY - BY MARIA DEUTSCHER . 3 HOURS AGOMitel closes deal to acquire Unify from AtosINFRA - BY ZEUS KERRAVALA . 4 HOURS AGOCrypto exchange Coinbase lands major regulatory approval in Singapore amid global expansionBLOCKCHAIN - BY KYT DOTSON . 5 HOURS AGOOn theCUBE Pod: Thoughts on Amazon investing in Anthropic and the FTC problemAI - BY RYAN STEVENS . 5 HOURS AGO 



 CUBE EVENT COVERAGE  help_outline
 LATEST FROM THECUBEWhat to expect during the “Beyond Firewalls: Resilience Strategies for All” event: Join theCUBE Oct. 19On theCUBE Pod: Thoughts on Amazon investing in Anthropic and the FTC problemWith the 'summer of data' in the rear-view mirror, here are the key takeaways to rememberRethinking digital asset management by simplifying file organization and retrievalHow Opus is helping frontline workers gain a competitive edge through blended learning
 DIVE INTO DAVE VELLANTE’S BREAKING ANALYSIS SERIEShelp_outlineCisco-Splunk under the microscope: Joint customers weigh inDave Vellante's Breaking Analysis: The complete collectionUber for everyone: Bob Muglia on how the future of data apps will evolveCloud security powers CrowdStrike's momentum. Gen AI is nextCopilot or competitor: How generative AI bolsters and buffets UiPath’s NorthStar aspirations








 


 UPCOMING CUBE EVENTSSEE MORE
 RECENT CUBE EVENTSDell Data Protection Series 2022-2023Future of Multicloud Lands Now - Dell Apex Cloud Platform for Microsoft Azure 2023Fal.Con 2023mWISE Conference 2023AWS Startup Showcase: Cybersecurity 2023SAS Explore 2023






 






















PRIVACY POLICY
TERMS
ABOUT US
CONTACT US
Sign Up
Send us a News tip




										2023 SiliconANGLE Media Inc. All rights reserved.
									



JOIN OUR COMMUNITY



theCUBE



Wikibon

















					    		×
					    	




Send us a News Tip

Name*


First



Last

Type of Pitch*Consumer or Enterprise?EnterpriseStartup NewsEmerging TechnologyEmail*

What's your story?*

FileNameThis field is for validation purposes and should be left unchanged.

  











 









					    		×
					    	













						    	×
						    


SIGN IN... Remember meLOGINForgot Password?ORNew User? SIGN UP





















Continue with Email...... Continue with Social Login 









						    	×
						    


SIGN UP





















Continue with Email...... Continue with Social Login 









						    	×
						    



Bio




Ethics Statement













						    	×
						    
EXTRACT THE SIGNAL FROM THE NOISE




Like Free Content? Subscribe to follow.

				                		Subscribe
				                	











CONTACT US

					    		×
					    	






























CookiesWe employ the use of cookies. Find out more.GOT IT! 

"
XA4C: eXplainable representation learning via Autoencoders revealing Critical genes,"Author summary We propose a gene expression data analysis tool, XA4C, which builds an eXplainable Autoencoder to reveal Critical genes. XA4C disentangles the black box of the neural network of an autoencoder by providing each gene’s contribution to the latent…",02-10-23,https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1011476,https://journals.plos.org/ploscompbiol/article/figure/image?id=10.1371/journal.pcbi.1011476.g005&size=inline, XAI,"








































































































































XA4C: eXplainable representation learning via Autoencoders revealing Critical genes | PLOS Computational Biology



















    Skip to main content
  

Advertisement











PLOS Computational Biology




  Browse 


Current Issue


Journal Archive


Collections


Find and Read Articles




    Publish
      


  Submissions 


Getting Started


Submission Guidelines


Figures


Tables


Supporting Information


LaTeX


Other Article Types


Preprints


Revising Your Manuscript


Submit Now




  Policies 


Best Practices in Research Reporting


Human Subjects Research


Animal Research


Competing Interests


Disclosure of Funding Sources


Licenses and Copyright


Data Availability


Code Availability


Complementary Research


Materials, Software and Code Sharing


Ethical Publishing Practice


Authorship


Corrections, Expressions of Concern, and Retractions




  Manuscript Review and Publication 


Editorial and Peer Review Process


Guidelines for Reviewers


Guidelines for Editors


Accepted Manuscripts


Comments







  About 


Journal Information


Editors-in-Chief


Editorial Board


Publishing Information


Publication Fees


Press and Media


Contact









Search
Search










      advanced search
    







 




Loading metrics







Open Access
Peer-reviewed

Research Article





XA4C: eXplainable representation learning via Autoencoders revealing Critical genes



Qing Li, 

Roles
    Data curation,

    Formal analysis,

    Investigation,

    Methodology,

    Software,

    Validation,

    Visualization,

    Writing – original draft,

    Writing – review & editing
  
Affiliation
    Department of Biochemistry & Molecular Biology, University of Calgary, Calgary, Canada
  
 ⨯ 




Yang Yu, 

Roles
    Data curation
  
Affiliation
    Department of Mathematics and Statistics, University of Calgary, Calgary, Canada
  
 ⨯ 




Pathum Kossinna, 

Roles
    Data curation,

    Software
  
Affiliation
    Department of Biochemistry & Molecular Biology, University of Calgary, Calgary, Canada
  
 ⨯ 




Theodore Lun, 

Roles
    Visualization
  
Affiliation
    Department of Biochemistry & Molecular Biology, University of Calgary, Calgary, Canada
  
 ⨯ 




Wenyuan Liao  , 

Roles
    Funding acquisition,

    Resources,

    Supervision
  
 * E-mail: wliao@ucalgary.ca (WL); qingrun.zhang@ucalgary.ca (QZ)
Affiliation
    Department of Mathematics and Statistics, University of Calgary, Calgary, Canada
  
 ⨯ 




Qingrun Zhang   

Roles
    Conceptualization,

    Formal analysis,

    Funding acquisition,

    Investigation,

    Methodology,

    Resources,

    Supervision,

    Validation,

    Writing – original draft,

    Writing – review & editing
  
 * E-mail: wliao@ucalgary.ca (WL); qingrun.zhang@ucalgary.ca (QZ)
Affiliations
    Department of Biochemistry & Molecular Biology, University of Calgary, Calgary, Canada, 
    Department of Mathematics and Statistics, University of Calgary, Calgary, Canada, 
    Alberta Children’s Hospital Research Institute, University of Calgary, Calgary, Canada, 
    Arnie Charbonneau Cancer Institute, University of Calgary, Calgary, Canada
  





        https://orcid.org/0000-0003-2701-0711
      



 ⨯ 








XA4C: eXplainable representation learning via Autoencoders revealing Critical genes

Qing Li, 

  
Yang Yu, 

  
Pathum Kossinna, 

  
Theodore Lun, 

  
Wenyuan Liao, 

  
Qingrun Zhang

  




x




Published: October 2, 2023

https://doi.org/10.1371/journal.pcbi.1011476










Article


Authors


Metrics


Comments


Media Coverage



Peer Review






Reader Comments

Figures












?
This is an uncorrected proof.


Figures



































AbstractMachine Learning models have been frequently used in transcriptome analyses. Particularly, Representation Learning (RL), e.g., autoencoders, are effective in learning critical representations in noisy data. However, learned representations, e.g., the “latent variables” in an autoencoder, are difficult to interpret, not to mention prioritizing essential genes for functional follow-up. In contrast, in traditional analyses, one may identify important genes such as Differentially Expressed (DiffEx), Differentially Co-Expressed (DiffCoEx), and Hub genes. Intuitively, the complex gene-gene interactions may be beyond the capture of marginal effects (DiffEx) or correlations (DiffCoEx and Hub), indicating the need of powerful RL models. However, the lack of interpretability and individual target genes is an obstacle for RL’s broad use in practice. To facilitate interpretable analysis and gene-identification using RL, we propose “Critical genes”, defined as genes that contribute highly to learned representations (e.g., latent variables in an autoencoder). As a proof-of-concept, supported by eXplainable Artificial Intelligence (XAI), we implemented eXplainable Autoencoder for Critical genes (XA4C) that quantifies each gene’s contribution to latent variables, based on which Critical genes are prioritized. Applying XA4C to gene expression data in six cancers showed that Critical genes capture essential pathways underlying cancers. Remarkably, Critical genes has little overlap with Hub or DiffEx genes, however, has a higher enrichment in a comprehensive disease gene database (DisGeNET) and a cancer-specific database (COSMIC), evidencing its potential to disclose massive unknown biology. As an example, we discovered five Critical genes sitting in the center of Lysine degradation (hsa00310) pathway, displaying distinct interaction patterns in tumor and normal tissues. In conclusion, XA4C facilitates explainable analysis using RL and Critical genes discovered by explainable RL empowers the study of complex interactions.

Author summary
We propose a gene expression data analysis tool, XA4C, which builds an eXplainable Autoencoder to reveal Critical genes. XA4C disentangles the black box of the neural network of an autoencoder by providing each gene’s contribution to the latent variables in the autoencoder. Next, a gene’s ability to contribute to the latent variables is used to define the importance of this gene, based on which XA4C prioritizes “Critical genes”. Notably, we discovered that Critical genes enjoy two properties: (1) Their overlap with traditional differentially expressed genes and hub genes are poor, suggesting that they indeed brought novel insights into transcriptome data that cannot be captured by traditional analysis. (2) The enrichment of Critical genes in a comprehensive disease gene database (DisGeNET) and cancer-specific database (COSMIC) are higher than differentially expressed or hub genes, evidencing their strong relevance to disease pathology. Therefore, we conclude that XA4C can reveal an additional landscape of gene expression data.

Citation: Li Q, Yu Y, Kossinna P, Lun T, Liao W, Zhang Q (2023) XA4C: eXplainable representation learning via Autoencoders revealing Critical genes. PLoS Comput Biol 19(10):
           e1011476.
        
        https://doi.org/10.1371/journal.pcbi.1011476Editor: Shihua Zhang, Academy of Mathematics and Systems Science, Chinese Academy of Science, CHINAReceived: April 30, 2023; Accepted: August 29, 2023; Published:  October 2, 2023Copyright:  © 2023 Li et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.Data Availability: XA4C is publicly available in our GitHub: https://github.com/QingrunZhangLab/XA4C TCGA: https://portal.gdc.cancer.gov/, BRCA: https://portal.gdc.cancer.gov/projects/TCGA-BRCA; COAD: https://portal.gdc.cancer.gov/projects/TCGA-COAD; KIRC: https://portal.gdc.cancer.gov/projects/TCGA-KIRC; LUAD: https://portal.gdc.cancer.gov/projects/TCGA-LUAD; PRAD: https://portal.gdc.cancer.gov/projects/TCGA-PRAD; THCA: https://portal.gdc.cancer.gov/projects/TCGA-THCA; DisGeNET: https://www.disgenet.org/search. Concept Unique Identifier (CUI) used for six cancers are listed as following: BRCA: C0678222, C0006142; COAD: C0009402, C0699790; KIRC: C1378703, C0007134, C0740457; LUAD: C0684249; PRAD: C0600139; THCA: C0549473 DESeq2: http://www.bioconductor.org/packages/release/bioc/html/DESeq2.html WGCNA: https://cran.r-project.org/web/packages/WGCNA/index.html COSMIC Cancer Gene Census: https://cancer.sanger.ac.uk/census.Funding: Q.Z. is supported by an NSERC Discovery Grant (RGPIN-2018-05147), a University of Calgary VPR Catalyst grant, and a New Frontiers in Research Fund (NFRFE-2018-00748). W.L. is partly supported by an NSERC CRD Grant (CRDPJ532227-18). Q.L. is partly supported by an Alberta Innovates LevMax-Health Program Bridge Funds (222300769). The computational infrastructure is funded by a Canada Foundation for Innovation JELF grant (36605) and an NSERC RTI grant (RTI-2021-00675). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.Competing interests:  The authors have declared that no competing interests exist.
IntroductionMachine learning (ML) models play increasingly important roles in gene expression analyses. Among many ML techniques, representation learning (RL) has the potential to bring a breakthrough, due to its ability to deconvolute nonlinear structures and denoise confounders [1]. For example, in the data preprocessing stage, in contrast to traditional statistical models that remove principal components to adjust data [2], modern tools can run RL to eliminate noise and possibly non-linear structures in the data [3–7]. Autoencoders (AE) have been extensively utilized to develop various tools for processing expression data [3–5, 8]. A notable feature of AEs is their ability to learn the hidden representations of input data despite the input being noisy and heterogeneous, leading to “latent variables” that are cleaner and more orthogonal for next stages of analysis.
However, such learned representations, although enjoying desirable statistical properties, are difficult to interpret. Therefore, in practice, researchers and clinical practitioners are left with manual inspection of data to decide whether to conduct experimental follow-up or clinical investigations. Additionally, traditional expression analyses naturally provide a list of prioritized genes. For instances, one may identify genes of importance such as Differentially Expressed genes (DiffEx) based on individual genes’ marginal effects [9–11] and Differentially Co-Expressed genes [12] based on genes’ pairwise correlations [13–15]. Also, Hub genes can be prioritized based on the connectivity of the nodes in a gene-gene co-expression network [13]. In contrast, the (usually uninterpretable) learned representations do not offer analogues for the experimentalists or clinicians to follow up. Although several tools supporting interpretable ML models are available [4, 8, 16], they do not offer individual candidate genes based on learned representations. In particular, Hanczar and colleagues employed gradient methods to analyze the contribution of specific neurons in the network [16], which, however, does not focus on the contribution of individual input genes. Dwivedi and colleagues analyzed the effect of an input feature by differentiating the outcome by switching off the focal input feature, i.e., gene [4]. Although aiming to relieve the problem of interpretation, this method only focuses on the marginal effect of each gene, which does not employ the latest development in eXplainable Artificial Intelligence (XAI) that systematically examines complex models. Recently, Withnell et al proposed XOmiVAE [8] that also employs SHAP and AE, however it focuses more on the classification of samples, instead of prioritizing individual genes for further analysis. Other efforts using XAI in the field of cancer and health outcomes [17–19] also do not prioritize individual genes. Therefore, to facilitate broader use of RL of expression data, interpretable tools that prioritize candidate genes are urgently needed.
Herein, supported by state-of-the-art development in XAI [20], we developed a tool, XA4C (eXplainable Autoencoder for Critical genes), to facilitate explainable analysis and prioritization of individual genes. Technically, XA4C is composed of two main components: First XA4C offers optimized autoencoders to process gene expressions at two levels: whole transcriptome (global) autoencoder, and single pathway (local) autoencoders (Materials and Methods). Second, using SHapley Additive exPlanations (SHAP) [21–23], a pioneering method inspired by the popular economic concept of “Shapley Value” quantifying the contribution of a player in a game, XA4C quantifies individual gene’s contribution to the learned latent variables in an autoencoder (Materials and Methods), and aggregate them to form “Critical index” for each gene (Materials and Methods). These Critical indexes will be used to prioritize Critical genes based on user specified cutoff, e.g., 1%.
The term “Critical gene”, reflecting genes substantially explaining of latent variables is comparable to the popular term “Hub gene” which is defined as the genes with high connectivity in a co-expression network [13]. These two could be considered in parallel because “Critical genes” and “Hub genes” both play a sensible role in gene-gene interactions, although in different forms of representations in an interaction network. In other words, “Hub genes” contribute to the surrounding genes in the co-expression network through correlations in the plain representation, whereas “Critical genes” contribute to linked genes through the latent variables in an autoencoder through explaining their variations. As hidden states presumably incorporate complex correlation structures, the links between genes and hidden states may be considered the analogue of links in a co-expression network, hence the analogous relationship between Hub genes and Critical genes.
By applying XA4C to cancer data offered by The Cancer Genome Atlas [24], or TCGA (Materials and Methods), we revealed sensible genes and pathways through SHAP-based explanations. We also carried out thorough investigations of Critical Genes by generating summary statistics in comparison to other conventional means, i.e., DiffEx genes and Hub genes. We observed important properties of Critical genes: first, the overlaps between Critical genes with DiffEx or Hub genes are quite low; and second, Critical genes’ enrichment in a comprehensive disease-gene database is higher than the ones of DiffEx and Hub genes. These indicate that Critical genes indeed revealed new candidates into the pathology, and they are even more sensible than the DiffEx and Hub genes revealed by traditional analysis. As a step further, we analyzed the data and discovered Critical genes (that are not DiffEx or Hub) altering the interaction patterns in Lysine degradation (hsa00310) pathway.

Results

The XA4C model
Autoencoder (AE) is a RL model that learns representations of input datasets in an unsupervised way [1, 25]. Based on an AE with fully connected neural network, XA4C first learns representations of gene expressions (Materials and Methods; Fig 1A). Briefly, input gene expression profiles are passed through the encoder network to learn low-dimensional representations through a bottleneck. The decoder is symmetrical to the encoder counterpart to recover the gene expressions. The loss function of training the parameters in the AE is Mean Squared Error (MSE) between input and output, the default for continuous variables. To quantify each gene’s contribution to the latent variables, XA4C employs eXtreme Gradient Boosting (XGBoost) [26], an ensemble tree model [27] between the input genes and latent variables (Materials and Methods; Fig 1B). Then, Tree SHAP explanation [23] is used to assess the contribution of inputs to representations (Materials and Methods; Fig 1B). As such, XA4C outputs SHAP values for input gene expression individually and quantifies the contribution of each input to each representation (i.e., latent variable). Using these SHAP values, XA4C further quantifies the Critical index of a gene by averaging the absolute values of its SHAP value to all latent variable via all the samples (Materials and Methods). By ordering these genes based on their Critical indexes, XA4C achieves a list of Critical genes above a user-specified cutoff, e.g., top 1% (Materials and Methods; Fig 1C). As downstream applications of XA4C, the genes together with their Critical indexes may be used for pathway enrichment analysis and connectivity analysis (Materials and Methods; Fig 1D and 1E).

          Download:
          PPTPowerPoint slidePNGlarger imageTIFForiginal imageFig 1.  The XA4C model and potential downstream analysis.(A) An autoencoder is constructed to learn representations (i.e., latent variables) of input gene expression profiles. (B) XGBoost and TreeSHAP are utilized to evaluate SHAP values and Critical indexes for all genes. (C) Critical genes are the ones with the top 1% Critical indexes. (D) KEGG pathway enrichment identifies sensible pathways overrepresented by prioritized genes with SHAP values. (E) Connectivity analysis discloses interaction patterns among genes centered by Critical genes in pathways.

              https://doi.org/10.1371/journal.pcbi.1011476.g001

Whole-transcriptome AEs with high compression ratio reconstructed with high accuracy
First, we established whole transcriptome AEs based on curated 15,000 genes (Materials and Methods). Second, we evaluated reconstruction performances for AEs by calculating R2 from testing samples (Table 1). It is observed that AEs with 32 latent variables conducted decent reconstruction with R2 values from the testing dataset varying from 0.42–0.69, which are comparable to AEs with 512 latent variables (R2 values range from 0.50–0.72). However, the compression ratio of AEs with 32 latent variables (468≈15,000/32) is 16 times of AEs with 512 nodes (29≈15,000/512), which indicates latent variables from the former compress way more information. Therefore, for the whole transcriptome analysis of XA4C, we used AEs with 32 latent variables nodes for the six cancers. We also set up this as the default in XA4C.

          Download:
          PPTPowerPoint slidePNGlarger imageTIFForiginal imageTable 1.  Test R2 for whole transcriptome autoencoders.L is the number of layers and H is the number of latent variables.

              https://doi.org/10.1371/journal.pcbi.1011476.t001

Whole-transcriptome Critical genes and pan-cancer pathways
We calculated Critical indexes for the ~15,000 genes (S1 Table) and illustrated the top 30 in Fig 2A. It is observed that the maximum absolute values for Critical indexes range from 0.03 to 0.06, and they decrease quickly. The overall distribution of the Critical indexes all genes and Critical genes in six cancers are in Fig 2B.

          Download:
          PPTPowerPoint slidePNGlarger imageTIFForiginal imageFig 2.  Whole transcriptome Critical indexes of genes in six cancers.(A) Genes with the largest 30 Critical indexes summarized among all latent variables and averaged across samples. (B) Distribution of whole transcriptome Critical indexes for all genes. (C) Distribution of whole transcriptome Critical indexes for Critical genes.

              https://doi.org/10.1371/journal.pcbi.1011476.g002We further conducted pathway over-representation analysis on genes with non-zero Critical indexes to reveal sensible pathways underlying cancers (Materials and Methods). We found a handful of pathways that mediate crucial roles in multiple cancers (Fig 3A and S2 Table). Notably, oxidative phosphorylation (OXPHOS) was enriched for five cancers (BRCA, COAD, KIRC, LUAD and THCA), and growing evidence indicate it was an active metabolic pathway in many cancers [28]. Higher expression of OXPHOS genes predicts improved survival in some cancers [29], but also confers chemotherapy resistance in others [30, 31]. Many recent studies proposed to treat this pathway as an emerging target for cancer therapy [29–31]. Another interesting pathway, glutathione metabolism, has been found in two cancers (KIRC and THCA). Glutathione (GSH) is an important antioxidant that maintains cellular redox homeostasis and detoxifies carcinogens [32, 33]. However, GSH metabolism can also play a pathogenic role in cancer by conferring therapeutic resistance and promoting tumor progression [33, 34]. There are novel therapies that target the GSH antioxidant system in tumors to increase treatment response and decrease drug resistance [33]. Furthermore, amino sugar and nucleotide sugar metabolism pathway has been identified LUAD, and studies showed that arresting pathways of carbohydrate metabolism such as central carbon metabolism in cancer, aerobic glycolysis, and amino sugar and nucleotide sugar metabolism can introduce apoptosis in breast cancer [35]. Other well-known cancer pathways, such as apoptosis, p53 signalling pathways, have also been discovered by Critical index-directed enrichment analysis.

          Download:
          PPTPowerPoint slidePNGlarger imageTIFForiginal imageFig 3.  Pathway enrichment of whole-transcriptome genes.(A) Top 20 KEGG pathways enriched by genes with non-zero Critical indexes. The p-values are listed in S2 Table. (B) Comparison of pathways enrichment of genes prioritized by XA4C, DiffEx analysis and DiffCoEx analysis.

              https://doi.org/10.1371/journal.pcbi.1011476.g003As comparisons, we also performed differential expression (DiffEx) analysis [36] and differential co-expression (DiffCoEx) analysis [12] (Materials and Methods). Overall, 31%~83% of XA4C pathways are shared with DiffEx, and the percentage increased to 76%~91% for DiffCoEx (Fig 3B). Our results showed that XA4C’s ability of identifying pathways has a larger overlap with the network-based approach DiffCoEx than the marginal effect-based approach DiffEx. It may because AE can handle nonlinear relationships among features, whereas traditional DiffEx analysis couldn’t utilize gene network information.


Overview of within-pathway Critical genes
To further explore the Critical genes within known pathways, we applied AEs to expressions of genes within individual pathways. From the KEGG [37], we downloaded 334 pathways whose numbers of genes varies from dozens to hundreds (S3 Table). For each pathway of each cancer, we constructed an AE, with a small number of latent variables (H = 8) and few layers (number of layers L = 3 or 2). We set L = 2 when the number of genes in a pathway is less than 100, or L = 3 otherwise. Pathway AEs testing R2 values have noteworthily high values with mean values above 0.6 for all six cancers (Fig 4A). It is also noted that the mean testing R2 values from KIRC, PRAD, and THCA pathway AEs are larger than BRCA, COAD and LUAD, which is consistent with the AEs performance of whole-transcriptome analysis. The distributions of Critical indexes for genes from 334 pathways are similar to whole-transcriptome results (S1A Fig) and pathway Critical genes (the largest 1%) mean values also approximate transcriptome Critical genes (S1B Fig).

          Download:
          PPTPowerPoint slidePNGlarger imageTIFForiginal imageFig 4.  Generation and analysis of within-pathway Critical genes.(A) Distribution of R2 (in testing samples) of pathway AEs in six cancers. (B) Overlaps between Critical genes and Hub genes (identified by WGCNA). (C) Overlaps between Critical genes and DiffEx genes. (D) Numbers of Critical, Hub, and DiffEx genes validated by DisGeNET. (E) Percentage of Critical, Hub, and DiffEx genes validated by DisGeNET.

              https://doi.org/10.1371/journal.pcbi.1011476.g004

Critical genes are highly enriched in cancer-related mutations
We conducted a comprehensive analysis of genetic and epigenetic mutations in the critical genes identified by XA4C. We first obtained information from the COSMIC database [38]: the genetic mutations, including missense mutations and copy number variations, and epigenetic mutations, including differential methylation. Based on the available mutation information, we observed a significant proportion of Critical genes (70% averaged for six cancers) that exhibited gained or lost copy number variations. Additionally, approximately 25% of the critical genes showed differential methylation, characterized by a beta-value difference larger than 0.5 compared to the average beta-value across the normal population. Furthermore, around 12% of the Critical genes displayed missense mutations, which have the potential to alter the function of the encoded proteins. The detailed results are listed in S4 Table.


The overlaps between Critical genes and Hub or DiffEx genes are poor
To reveal whether Critical genes indeed make differences in practice, we compare Critical genes to Hub genes defined by Weighted Correlation Network Analysis (WGCNA) [13] as well as DiffEx genes generated by DESeq2 [36] (Materials and Methods). As WGCNA outputs 1 Hub gene per pathway and our 1% Critical index cut-off in the pathway is on average approximately 1 or 2 genes, this analysis yields comparable number of genes. We found that, in all six cancers, the overlap between Critical genes and Hub genes are poor (Fig 4B) Similar observation is also evident for DiffEx genes (Fig 4C). These results show that Critical genes indeed provide a different angle for researchers to analyze expression data.


Critical genes have higher enrichment in disease genes than Hub and DiffEx
Having learned the low overlap presented above, we then continue to learn whether the Critical genes prioritized by XA4C are indeed sensible. We then examined the DisGeNET [39], a comprehensive database for the enrichment of these three categories of genes (Materials and Methods). We noticed that Critical genes are highly enriched in genes with susceptibility reported in DisGeNET. Although DiffEx has the number of successfully validated genes due to its overall substantially more input candidates (Fig 4D), Critical gene is the winner when comparing the ratio (numbers of validated genes divided by numbers of input genes) (Fig 4E). Notably, the high proportions are consistent across all six cancers, indicating that Critical genes are fundamental for all cancers. We also tried to replicate such enrichment analysis in the COSMIC database that focuses more on mutations. The success rates of all three methods (Critical, Hub and DiffEx genes) are low (S5 Table). However, the limited data still indicates the advantage of Critical genes which has higher success rate in majority of cancers compared to alternatives (S5 Table).
Using DisGeNET as gold-standard, we also quantitatively calculated the confusion matrices as well as precision, recall, F1-score and accuracy for all three methods (Materials and Methods). The results, presented in (S6 and S7 Tables), demonstrate that XA4C outperforms the other methods in terms of F1-score (largely contributed by its supremacy on precision), and the accuracy of the three methods are comparable.
Together, these results indicate that XA4C-derived Critical genes capture additional information other than marginally altered gene expression and genes with a high degree of connectivity in the protein-protein interaction network.


Critical genes alter interaction patterns in a pan-cancer pathway
To further investigate the functions performed by Critical genes in their pathways, we calculated the Pearson correlation between the Critical genes and all the other genes in corresponding pathways. We found that Critical genes display distinct interaction patterns in the co-expression network between tumor and matched normal tissues. We specifically picked up an example in Lysine degradation (I00310) pathway as the Critical genes in this pathway are neither Hub nor DiffEx genes in five cancers. Evidently, the interaction patterns of Critical genes and surrounding genes are dramatically different in five cancers, which are visible by inspections and quantified by the Kolmogorov-Smirnov test (Fig 5). First, the intensity of correlation is notably weaker in tumor while compared to normal (lighter color in tumor and brighter color in normal). Moreover, the variance of correlations (reflected by the height of the boxplots) is substantially larger in normal tissues in all cancers except for THCA. Overall, the dramatically changed interaction patterns suggest that Critical genes involved in disease pathogenesis through interactions with other genes although themselves are not marginally differentially expressed (DiffEx genes) nor most connected with other genes (Hub genes) in the pathway.

          Download:
          PPTPowerPoint slidePNGlarger imageTIFForiginal imageFig 5.  Critical genes show distinct co-expression networks in tumor and normal tissues.The Lysine degradation pathway (I00310) is used. Critical genes (light blue) are located at the core of the network, surrounded by additional genes from the same pathway (gray). The boundaries of Pearson’s correlation coefficients range from +0.8 (red) to -0.8 (blue). Boxplots show the distributions of two sets of correlations (tumor vs. normal) together with the P-value of the Kolmogorov-Smirnov test, with the null hypothesis being that the two samples were chosen from the same distribution. Critical genes shown in this figure are novel as they have not been identified by traditional analysis search for Hub nor DiffEx genes.

              https://doi.org/10.1371/journal.pcbi.1011476.g005

DiscussionIn this work, we proposed XA4C, an XAI empowered AE tool to support explainable representation learning (RL). A notable contribution of XA4C is the definition of Critical genes, which formed the RL analogue to Hub/DiffEx genes, bringing an additional perspective in characterizing transcription data. By applying XA4C to cancer transcriptomes, XA4C generated Critical indexes and the list of Critical genes. Analyses show that Critical genes are quite different to DiffEx and Hub genes offered standard analysis based on plain representations, opening a potential landscape for in-depth analysis of complex interactions using RL. Impressively, Critical genes enjoy higher success rate in DisGeNET, a comprehensive disease gene database, indicating that Critical genes indeed play functional roles in diseases. As an example of interactions revealed by Critical genes, XA4C highlighted interesting Critical genes playing central roles in pathways by showing distinct the interaction patterns between tumor and normal tissues.
Machine learning algorithms may run into overfitting. In XA4C, there are two models used: Autoencoder and TreeSHAP. The autoencoder by itself is unsupervised, therefore, it may not run into overfitting [40, 41]. More importantly, a sparsity penalty with L1 regularization is applied to XA4C autoencoder loss function, which penalizes non-zero activations. This sparsity penalty can prevent overfitting to some extent because it makes the autoencoder prefer to activate only a subset of its nodes. It also helps generalization by preventing the model from remembering noisy or irrelevant patterns in the training data [42, 43]. It is important to note that TreeSHAP itself does not introduce overfitting if the underlying tree model is not overfitting. In our study, we employed the XGBoost regression model as the tree model. XGBoost models also incorporate regularization techniques to prevent overfitting [44, 45]. With the regularization penalty in both the autoencoder and TreeSHAP, we believe the overfitting is under control in our XA4C model.
To compare whether our protocol using Autoencoder + SHAP indeed outperforms the built-in feature importance values generated by other models, we conducted some comparisons to two representative tools, namely Random Forest and XGBoost. We trained classifiers using Random Forest and XGBoost using established tools [26, 46] and then use their corresponding feature importance values to define “Important genes” analogue to our procedure of defining Critical genes using SHAP values (Materials and Methods). We observed that, despite the classification accuracy of Random Forest or XGBoost being excellent (S8 Table), the “Importance genes” prioritized by Random Forest or XGBoost (listed in S9 Table) have much less functional enrichment in both DisGeNET and COSMIC databases (S10 Table).
We acknowledge limitations of XA4C, which could be addressed by our future work. First, we utilized fixed architectures of AEs in this study. Although we compared the performances of AEs on several different architectures and selected the optimal architectures for whole-transcriptome (L = 5, H = 32) and pathway AEs (L = 3 or 2, H = 8), we only tested a few combinations of the architecture parameters. A sophisticated way is to incorporate Bayesian Hyperparameter Optimization[47] for extensively evaluating the combinations of L and H. Second, only conventional AEs are used. It is straightforward to extend to other AEs, such as Variational AE for causal inference and Graph AE to learn causal structure, which is our planned future work. Third, TreeSHAP was utilized in this study to explain the tree model built on AEs inputs and representations. Some SHAP explainers, such as DeepSHAP [48], might be more efficient for neural network models since they omit the phase of constructing Tree models between inputs and representations. Fourth, we summarized SHAP values over samples to generate one Critical index to rank the importance of genes. This gives us general information but ignores the heterogeneity between individual samples. Our future study will focus on individuals to uncover individualized Critical genes to support precision medicine. Finally, XA4C currently supports only transcriptome data, and a natural extension will be the incorporation of additional omics data, such as proteomics and metabolomics.

Materials and methods

XA4C model (I): Autoencoder (AE) architectures and parameters tuning
AE consists of two main components: an encoder and a decoder. The encoder converts the input data into a lower-dimensional representation, known as the “latent variables”. The decoder then reconstructs the original input data based on latent variables. The objective of an autoencoder is to minimize the reconstruction error between the input data and the reconstructed. From a mathematical perspective, the encoder part can be represented by the encoding function h = f(x), and the decoder can be represented by the decoding function r = g(h). Thus, the whole AE can be described by a function r = g(f(x)), where the output r is reconstructed as approximate as possible to the original input x. XA4C utilizes Mean Square Error  as the loss function.
By default, XA4C specifies an AE with 5 coding layers and 32 latent variables for whole transcriptome, and Aes with 3 coding layers (or 2 if the number of genes is lower than 100) and 8 latent variables for pathway gene expressions. We achieved these optimal parameters by testing configurations striking a balance between fewer AE parameters (layers, nodes) and a larger reconstruction R2 in testing sample. To train AE models, we partitioned tumor samples into training and testing datasets with the ratio of 8:2. Genes with median expression levels larger than 1.0 were retained as input. Raw gene expressions were transformed using Log (base 2) function, and then further rescaled to a range between 0 and 1 to match the sigmoid activation function in AE neural networks. To train AE models, we utilized the Adam optimizer [49] with a learning rate = 1.0 × 10−3 and decay = 0.8 for 500 epochs. The training stops when testing R2 does not increase by more than 0.02% in 10 epochs, or the maximum number of training epochs (3,000) is reached. The batch size was set as the input sample size. These AE models were implemented using PyTorch [50].


XA4C model (II): Shapley Additive exPlanation (SHAP) framework, XGBoost and TreeSHAP
SHAP is a classical post-hoc explanatory framework to calculate the contribution of each input variable in each sample learn the explanatory effect [21]. Let f be the original model and f(x) the predicted values. g(x′) is the explanation model used to match the original model f(x). Note that explanation models often use simplified inputs x′ that map to the original inputs through a mapping function x = hx(x′). XA4C incorporates XGBoost Regressor [26] to represent the model f and Tree Explainer [23] as the model g to interpret f in SHAP. We choose XGBoost because models built through gradient boosting algorithm gives more importance to functional features and are less vulnerable to hyperparameters initializations [51]. Each latent variable has an XGBoost model. TreeSHAP is a SHAP method designed for the black-box tree models including Random Forest, XGBoost, and CatBoost, etc [52].For each XGBoost regression model (established between all inputs and a latent variable in the AE), XA4C carries out TreeSHAP calculation, leading to a SHAP value for each triple of [gene, latent variable, sample].


XA4C model (III): definition of Critical indexes and Critical genes
The Critical index of a gene is the weighted average of its SHAP value contributed to all samples and all latent variables. To calculate the Critical index (WSVi) of gene i, XA4C first takes the mean absolute value for the gene i over all n samples, leading to the SHAP value of a gene to a latent variable:

Then, XA4C summarizes SHAP values (SVh,i) across all latent variables (e.g., 32 in the default AE configuration of XA4C) and weights them by wh, which is the XGBoost regressor R2 of the h-th latent variable:

XA4C ranks all genes based on their Critical indexes and take the top ones (based on a user-specified cutoff) as Critical genes. By default, XA4C selects 1% for both whole transcriptome is and within-pathway analysis. The ceiling function ⌈*⌉, i.e., the least integer greater than the actual value (e.g., ⌈0.2⌉ = 1,⌈1.8⌉ = 2), is used when the cut-off is not an integer.


TCGA gene expression data for six cancers
We utilized gene expression (number of genes M = 56,497)) from six cancers (BRCA: breast invasive carcinoma, COAD: colon adenocarcinoma, KIRC: kidney renal clear cell carcinoma, LUAD: lung adenocarcinoma, PRAD: prostate adenocarcinoma, THCA: thyroid carcinoma) from The Cancer Genome Atlas (TCGA) [24]. The raw count data was downloaded from the TCGA data portal and then converted to Transcripts Per Million (TPM) gene expression matrices using gene lengths obtained through the BioMart package (code available in our GitHub). We then performed basic quality control to examine the overall structure of the data by PCA analysis [53] and did not find unexpected data points. In particular, we curated genes with median expression levels higher than 1.0, which reduces interference from lowly expressed genes and the number of genes decreased to around 15K. We also performed log-2 transformation to these 15K genes. When applying XA4C to cancer data, for each cancer type, one whole-transcriptome AE and 334 pathway Aes were trained independently. The architecture of the embedding network contains 32 latent variables for whole-transcriptome AE or 8 latent variables for pathway Aes. These whole-transcriptome or pathway representations and their corresponding inputs were passed through the XGBoost regression model on which TreeSHAP SHAP values for inputs genes.


Pathway over-representation analysis
Over-representation analysis (ORA) [54] is a statistical method to understand which biological pathways may be over-represented. It determines whether genes from pre-defined sets (e.g., those belonging to a specific KEGG pathway) are present more than would be expected (over-represented). The p-value can be calculated by the hypergeometric distribution: , where N is the total number of genes in the background set, n represents the size of the list of genes of interest (for example the number of DiffEx or Critical genes), M stands for the number of genes annotated background, and k is the number of genes in the list annotated to the gene set. The background distribution, by default, is all the genes that have annotation, which are KEGG pathway genes in this study. We utilized the ORA analysis provide by the R package named WebGestalt [55].


Differential expression genes, Differential Co-expression genes and hub genes Analysis
Differential expression (DiffEx) analysis aims at identifying differentially expressed genes between experimental groups. We utilized DESeq2 [36], which tests for differential expression by negative binomial generalized linear models [36], with default parameters. DESeq2 employs a generalized linear model framework with a negative binomial distribution to assess differential expression between two groups. Initially, it estimates the fold change for each gene between the groups, and subsequently calculates the Wald test statistics and corresponding p-values. These p-values reflect the level of evidence contradicting the null hypothesis that there is no disparity in gene expression between the conditions. These p-values are further adjusted for multi-test correction, and the significance level (alpha) utilized is 0.05, a conventional parameter for statistical tests.
As DiffEx analysis is based on linear models, it ignores the non-linearity displayed by gene expression. Therefore, we used differential co-expression networks to identify groups (or “modules”) of differentially co-expressed genes utilizing “DiffCoEx” [12], an extension of the WGCNA[13]. DiffCoEx begins with the construction of two adjacency matrices:  for case samples and Ccontrol similarly for control samples. DiffCoEx used the Spearman rank correlation, and a matrix of adjacency difference is then calculated:

where β ≥ 0 is an integer tuning parameter which can be selected in multiple ways. In this study, we chose β ∈ [5,6,7,8,9,10] such that we achieved minimum number of modules with the largest module containing the smallest number of genes. Next, a Topological Overlap dissimilarity Matrix is calculated where smaller values of tij indicates that a pair of genes genei, and genej have significant correlation changes (between case and control).
Finally, the dissimilarity matrix T is to identify DiffCoEx genes.
Hub genes, highly connected within biological networks, were identified using gene co-expression networks constructed with WGCNA. We utilized the ""chooseTopHubInEachModule"" function from the WGCNA R package, applying it to the gene expression matrix from pathways. Default settings were maintained, with the power parameter of 2 and the type parameter of ""signed.""


Performance measurements of accuracy and sensitivity
In this evaluation, we compare the performance of Critical genes, Hub genes, and DiffEx genes using quantified performance measurements. We first construct confusion matrices. Considering DisGeNET-reported genes as the gold-standard. For a particular tool (critical genes, hub genes, or DiffEx genes), we defined true positives (TP) as genes identified by the tool and are reported by DisGeNET, true negatives (TN) as genes not identified and not reported in DisGeNET, false positives (FP) as genes identified but not reported in DisGeNET, and false negatives (FN) as genes identified but not reported in DisGeNET. Based on the confusion matrices, we calculated precision, recall, F1 score and accuracy using the formula below:






Comparison to the feature importance values generated by Random Forest and XGBoost
The Random Forest and XGBoost classifiers were trained on gene expressions from 335 pathways. The classifiers were trained using default parameter settings with 500 estimators (number of trees in the forest). To ensure balanced representation of tumor and normal samples, we randomly sampled from tumor samples with the same number of normal tissue samples to construct datasets (S8 Table). The resulting dataset was then divided into training and test datasets in a 7:3 ratio. We performed model optimization on training datasets and evaluated its performance on test datasets. Notably, the classifiers exhibited impressive performance, as indicated by high weighted-averaged F1 scores across the 335 pathways. Specifically, the Random Forest classifier achieved an F1 score of 94% for six cancers, while the XGBoost classifier achieved an F1 score of 92% for the same six cancers (S8 Table). Subsequently, feature importance values were derived from these well-trained classifiers. The same procedure in the identification of Critical genes was used to define the ""Important genes"", defined as genes with top 1% ceiling importance values from classifiers in each pathway.


Supporting informationS1 Fig. Pathway Critical indexes of genes in six cancers.(A) Distribution of pathway Critical indexes for all genes in the corresponding pathways. (B) Distribution of pathway Critical indexes for Critical genes in the corresponding pathways.
https://doi.org/10.1371/journal.pcbi.1011476.s001(TIF)
S1 Table. Critical indexes for whole transcriptome AEs in six cancers.https://doi.org/10.1371/journal.pcbi.1011476.s002(XLSX)
S2 Table. KEGG pathways enrichment for XA4C, DiffEx and DiffCoEx.https://doi.org/10.1371/journal.pcbi.1011476.s003(XLSX)
S3 Table. . KEGG pathways and numbers of genes in pathways.https://doi.org/10.1371/journal.pcbi.1011476.s004(XLSX)
S4 Table. XA4C-identified critical genes in pathways associated with copy number variations, differential methylation, and genetic mutations from COSMIC database.https://doi.org/10.1371/journal.pcbi.1011476.s005(XLSX)
S5 Table. Number and Percentage of COSMIC Cancer-Specific Census Genes Identified by Critical Genes, Hub Genes, and DiffEx Genes.https://doi.org/10.1371/journal.pcbi.1011476.s006(XLSX)
S6 Table. Confusion Matrix for Critical Genes, Hub Genes, and DiffEx Genes Using DisGeNET as the Gold Standard.https://doi.org/10.1371/journal.pcbi.1011476.s007(XLSX)
S7 Table. Evaluation of Classification Performance for Critical Genes, Hub Genes, and DiffEx Genes Using DisGeNET as the Gold Standard.https://doi.org/10.1371/journal.pcbi.1011476.s008(XLSX)
S8 Table. Weighted-Averaged F1 Scores for 335 Pathways with Train and Test Sample Sizes.https://doi.org/10.1371/journal.pcbi.1011476.s009(XLSX)
S9 Table. Important (top 1% ceiling) genes identified by Random Forests and XGBoost.https://doi.org/10.1371/journal.pcbi.1011476.s010(XLSX)
S10 Table. Enrichment of critical genes, hub genes, DiffEx genes, important genes from Random Forests and XGBoost in DisGeNET and COSMIC Cancer Census Genes.https://doi.org/10.1371/journal.pcbi.1011476.s011(XLSX)

References1.
            Goodfellow I, Bengio Y, Courville A. Deep learning: MIT press; 2016. 2.
            Stegle O, Parts L, Piipari M, Winn J, Durbin R. Using probabilistic estimation of expression residuals (PEER) to obtain increased power and interpretability of gene expression analyses. Nat Protoc. 2012;7(3):500–7.  pmid:22343431 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    3.
            Taroni JN, Grayson PC, Hu QW, Eddy S, Kretzler M, Merkel PA, et al. MultiPLIER: A Transfer Learning Framework for Transcriptomics Reveals Systemic Features of Rare Disease. Cell Syst. 2019;8(5):380-+.  pmid:31121115 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    4.
            Dwivedi SK, Tjarnberg A, Tegner J, Gustafsson M. Deriving disease modules from the compressed transcriptional space embedded in a deep autoencoder. Nat Commun. 2020;11(1).  pmid:32051402 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    5.
            Jiayi B, Qing L, Albert L, Guotao Y, Jun Y, Jingjing W, et al. Autoencoder-transformed transcriptome improves genotype-phenotype association studies. bioRxiv. 2023. https://doi.org/10.1101/2023.07.23.550223. 
                      View Article
                    
                      Google Scholar
                    6.
            Eraslan G, Simon LM, Mircea M, Mueller NS, Theis FJ. Single-cell RNA-seq denoising using a deep count autoencoder. Nat Commun. 2019;10.  pmid:30674886 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    7.
            Tran D, Nguyen H, Tran B, La Vecchia C, Luu HN, Nguyen T. Fast and precise single-cell data analysis using a hierarchical autoencoder. Nat Commun. 2021;12(1).  pmid:33589635 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    8.
            Withnell E, Zhang XY, Sun K, Guo YK. XOmiVAE: an interpretable deep learning model for cancer classification using high-dimensional omics data. Brief Bioinform. 2021;22(6).  pmid:34402865 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    9.
            Auer PL, Doerge RW. A Two-Stage Poisson Model for Testing RNA-Seq Data. Statistical Applications in Genetics and Molecular Biology. 2011;10(1).  
                      View Article
                    
                      Google Scholar
                    10.
            Leek JT, Monsen E, Dabney AR, Storey JD. EDGE: extraction and analysis of differential gene expression. Bioinformatics. 2006;22(4):507–8.  pmid:16357033 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    11.
            Wang LK, Feng ZX, Wang X, Wang XW, Zhang XG. DEGseq: an R package for identifying differentially expressed genes from RNA-seq data. Bioinformatics. 2010;26(1):136–8.  pmid:19855105 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    12.
            Tesson BM, Breitling R, Jansen RC. DiffCoEx: a simple and sensitive method to find differentially coexpressed gene modules. BMC Bioinformatics. 2010;11.  pmid:20925918 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    13.
            Langfelder P, Horvath S. WGCNA: an R package for weighted correlation network analysis. BMC Bioinformatics. 2008;9.  pmid:19114008 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    14.
            Santos SD, Galatro TFD, Watanabe RA, Oba-Shinjo SM, Marie SKN, Fujita A. CoGA: An R Package to Identify Differentially Co-Expressed Gene Sets by Analyzing the Graph Spectra. PLoS One. 2015;10(8).  pmid:26313749 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    15.
            Zhu L, Ding Y, Chen CY, Wang L, Huo ZG, Kim S, et al. MetaDCN: meta-analysis framework for differential co-expression network detection with an application in breast cancer. Bioinformatics. 2017;33(8):1121–9.  pmid:28031185 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    16.
            Hanczar B, Zehraoui F, Issa T, Arles M. Biological interpretation of deep neural network for phenotype prediction based on gene expression. BMC Bioinformatics. 2020;21(1).  pmid:33148191 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    17.
            Yagin FH, Cicek IB, Alkhateeb A, Yagin B, Colak C, Azzeh M, et al. Explainable artificial intelligence model for identifying COVID-19 gene biomarkers. Comput Biol Med. 2023;154:106619. Epub 2023/02/05.  pmid:36738712 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    18.
            Yagin FH, Alkhateeb A, Colak C, Azzeh M, Yagin B, Rueda L. A Fecal-Microbial-Extracellular-Vesicles-Based Metabolomics Machine Learning Framework and Biomarker Discovery for Predicting Colorectal Cancer Patients. Metabolites. 2023;13(5). Epub 2023/05/26.  pmid:37233630 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    19.
            Rosen-Zvi M, Mullen L, Lukas RJ, Guindy M, Gabrani M. Editorial: Explainable multimodal AI in cancer patient care: how can we reduce the gap between technology and practice? Front Med (Lausanne). 2023;10:1190429. Epub 2023/05/01.  pmid:37122326 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    20.
            Gunning D, Stefik M, Choi J, Miller T, Stumpf S, Yang GZ. XAI-Explainable artificial intelligence. Science Robotics. 2019;4(37).  pmid:33137719 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    21.
            Lundberg SM, Lee SI. A Unified Approach to Interpreting Model Predictions. Advances in Neural Information Processing Systems. 2017;30.  
                      View Article
                    
                      Google Scholar
                    22.
            Shapley LS. A value for n-person games. Contributions to the Theory of Games II. 1953:307–17.  
                      View Article
                    
                      Google Scholar
                    23.
            Gillies S. The Shapely user manual. URL: https://pypiorg/project/Shapely. 2013. 
                      View Article
                    
                      Google Scholar
                    24.
            Weinstein JN, Collisson EA, Mills GB, Shaw KRM, Ozenberger BA, Ellrott K, et al. The Cancer Genome Atlas Pan-Cancer analysis project. Nat Genet. 2013;45(10):1113–20.  pmid:24071849 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    25.
            Hollensen P, Trappenberg TP. An Introduction to Deep Learning. Lect Notes Artif Int. 2015;9091. 
                      View Article
                    
                      Google Scholar
                    26.
            Chen T, He T, Benesty M, Khotilovich V, Tang Y, Cho H, et al. Xgboost: extreme gradient boosting. R package version 04–2. 2015;1(4):1–4. 
                      View Article
                    
                      Google Scholar
                    27.
            Berk RA. An introduction to ensemble methods for data analysis. Sociol Method Res. 2006;34(3):263–95.  
                      View Article
                    
                      Google Scholar
                    28.
            Nayak AP, Kapur A, Barroilhet L, Patankar MS. Oxidative Phosphorylation: A Target for Novel Therapeutic Strategies Against Ovarian Cancer. Cancers (Basel). 2018;10(9).  pmid:30231564 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    29.
            Frederick M, Skinner HD, Kazi SA, Sikora AG, Sandulache VC. High expression of oxidative phosphorylation genes predicts improved survival in squamous cell carcinomas of the head and neck and lung. Sci Rep. 2020;10(1):6380. Epub 2020/04/15.  pmid:32286489 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    30.
            Evans KW, Yuca E, Scott SS, Zhao M, Paez Arango N, Cruz Pico CX, et al. Oxidative Phosphorylation Is a Metabolic Vulnerability in Chemotherapy-Resistant Triple-Negative Breast Cancer. Cancer Res. 2021;81(21):5572–81. Epub 2021/09/15.  pmid:34518211 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    31.
            Ashton TM, McKenna WG, Kunz-Schughart LA, Higgins GS. Oxidative Phosphorylation as an Emerging Target in Cancer Therapy. Clin Cancer Res. 2018;24(11):2482–90. Epub 2018/02/09.  pmid:29420223 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    32.
            Balendiran GK, Dabur R, Fraser D. The role of glutathione in cancer. Cell Biochem Funct. 2004;22(6):343–52. Epub 2004/09/24.  pmid:15386533 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    33.
            Bansal A, Simon MC. Glutathione metabolism in cancer progression and treatment resistance. J Cell Biol. 2018;217(7):2291–8. Epub 2018/06/20.  pmid:29915025 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    34.
            Kennedy L, Sandhu JK, Harper ME, Cuperlovic-Culf M. Role of Glutathione in Cancer: From Mechanisms to Therapies. Biomolecules. 2020;10(10).  pmid:33050144 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    35.
            Ma S, Wang F, Zhang C, Wang X, Wang X, Yu Z. Cell metabolomics to study the function mechanism of Cyperus rotundus L. on triple-negative breast cancer cells. BMC Complement Med Ther. 2020;20(1):262. Epub 2020/08/28.  pmid:32843016 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    36.
            Love MI, Huber W, Anders S. Moderated estimation of fold change and dispersion for RNA-seq data with DESeq2. Genome Biol. 2014;15(12).  pmid:25516281 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    37.
            Ogata H, Goto S, Fujibuchi W, Kanehisa M. Computation with the KEGG pathway database. Biosystems. 1998;47(1–2):119–28.  pmid:9715755 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    38.
            Forbes S, Clements J, Dawson E, Bamford S, Webb T, Dogan A, et al. Cosmic 2005. Br J Cancer. 2006;94(2):318–22. Epub 2006/01/20.  pmid:16421597 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    39.
            Pinero J, Queralt-Rosinach N, Bravo A, Deu-Pons J, Bauer-Mehren A, Baron M, et al. DisGeNET: a discovery platform for the dynamical exploration of human diseases and their genes. Database (Oxford). 2015;2015:bav028. Epub 2015/04/17.  pmid:25877637 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    40.
            Michelucci U. An introduction to autoencoders. arXiv. 2022. https://doi.org/10.48550/arXiv.2201.03898. 
                      View Article
                    
                      Google Scholar
                    41.
            Lorbeer B, Botler M. Anomaly Detection with Partitioning Overfitting Autoencoder Ensembles. Proc Spie. 2022;12084.  
                      View Article
                    
                      Google Scholar
                    42.
            Zhang CF, Cheng X, Liu JH, He J, Liu GW. Deep Sparse Autoencoder for Feature Extraction and Diagnosis of Locomotive Adhesion Status. J Control Sci Eng. 2018;2018.  
                      View Article
                    
                      Google Scholar
                    43.
            Meng LH, Ding SF, Xue Y. Research on denoising sparse autoencoder. Int J Mach Learn Cyb. 2017;8(5):1719–29.  
                      View Article
                    
                      Google Scholar
                    44.
            Chen TQ, Guestrin C. XGBoost: A Scalable Tree Boosting System. Kdd’16: Proceedings of the 22nd Acm Sigkdd International Conference on Knowledge Discovery and Data Mining. 2016:785–94.  
                      View Article
                    
                      Google Scholar
                    45.
            Gomez-Rios A, Luengo J, Herrera F. A Study on the Noise Label Influence in Boosting Algorithms: AdaBoost, GBM and XGBoost. Hybrid Artificial Intelligent Systems, Hais 2017. 2017;10334:268–80.  
                      View Article
                    
                      Google Scholar
                    46.
            Pedregosa F, Varoquaux G, Gramfort A, Michel V, Thirion B, Grisel O, et al. Scikit-learn: Machine learning in Python. the Journal of machine Learning research. 2011;12:2825–30. 
                      View Article
                    
                      Google Scholar
                    47.
            Wu J, Chen X-Y, Zhang H, Xiong L-D, Lei H, Deng S-H. Hyperparameter optimization for machine learning models based on Bayesian optimization. Journal of Electronic Science and Technology. 2019;17(1):26–40. 
                      View Article
                    
                      Google Scholar
                    48.
            Davagdorj K, Bae JW, Pham V, Theera-Umpon N, Ryu KH. Explainable Artificial Intelligence Based Framework for Non-Communicable Diseases Prediction. Ieee Access. 2021;9:123672–88.  
                      View Article
                    
                      Google Scholar
                    49.
            Kingma DP, Ba J. Adam: A method for stochastic optimization. arXiv. 2014;arXiv:1412.6980. 
                      View Article
                    
                      Google Scholar
                    50.
            Paszke A, Gross S, Massa F, Lerer A, Bradbury J, Chanan G, et al. PyTorch: An Imperative Style, High-Performance Deep Learning Library. Advances in Neural Information Processing Systems. 2019;32. 
                      View Article
                    
                      Google Scholar
                    51.
            Wade C, Glynn K. Hands-On Gradient Boosting with XGBoost and scikit-learn: Perform accessible machine learning and extreme gradient boosting with Python: Packt Publishing Ltd; 2020. 52.
            Lundberg SM, Erion GG, Lee S-I. Consistent individualized feature attribution for tree ensembles. arXiv preprint arXiv:14126980. 2018;1802.03888. 
                      View Article
                    
                      Google Scholar
                    53.
            Abdi H, Williams LJ. Principal component analysis. Wiley interdisciplinary reviews: computational statistics. 2010;2(4):433–59. 
                      View Article
                    
                      Google Scholar
                    54.
            Boyle EI, Weng SA, Gollub J, Jin H, Botstein D, Cherry JM, et al. GO::TermFinder—open source software for accessing Gene Ontology information and finding significantly enriched Gene Ontology terms associated with a list of genes. Bioinformatics. 2004;20(18):3710–5.  pmid:15297299 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    55.
            Liao YX, Wang J, Jaehnig EJ, Shi ZA, Zhang B. WebGestalt 2019: gene set analysis toolkit with revamped UIs and APIs. Nucleic Acids Res. 2019;47(W1):W199–W205.  pmid:31114916 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    












Download PDF

 
    
Citation
XML






Print


    Share
    
Reddit
Facebook
LinkedIn
Mendeley
Twitter
Email






     







Advertisement






Subject Areas ?

For more information about PLOS Subject Areas, click
        here.
We want your feedback. Do these Subject Areas make sense for this article? Click the target next to the incorrect Subject Area and let us know. Thanks for your help!


    



Gene expression
 
Is the Subject Area ""Gene expression"" applicable to this article?
          Yes
No
Thanks for your feedback.



Cancers and neoplasms
 
Is the Subject Area ""Cancers and neoplasms"" applicable to this article?
          Yes
No
Thanks for your feedback.



Breast cancer
 
Is the Subject Area ""Breast cancer"" applicable to this article?
          Yes
No
Thanks for your feedback.



Thyroid carcinoma
 
Is the Subject Area ""Thyroid carcinoma"" applicable to this article?
          Yes
No
Thanks for your feedback.



Lung and intrathoracic tumors
 
Is the Subject Area ""Lung and intrathoracic tumors"" applicable to this article?
          Yes
No
Thanks for your feedback.



Prostate cancer
 
Is the Subject Area ""Prostate cancer"" applicable to this article?
          Yes
No
Thanks for your feedback.



Renal cancer
 
Is the Subject Area ""Renal cancer"" applicable to this article?
          Yes
No
Thanks for your feedback.



Transcriptome analysis
 
Is the Subject Area ""Transcriptome analysis"" applicable to this article?
          Yes
No
Thanks for your feedback.












Publications
PLOS Biology
PLOS Medicine
PLOS Computational Biology
PLOS Genetics
PLOS Pathogens
PLOS ONE
PLOS Neglected Tropical Diseases




 
PLOS Climate
PLOS Digital Health
PLOS Global Public Health
PLOS Sustainability and Transformation
PLOS Water

PLOS Complex Systems


PLOS Mental Health






Home


Blogs


Collections


Give feedback


LOCKSS





Privacy Policy
Terms of Use
Advertise
Media Inquiries
Contact






PLOS is a nonprofit 501(c)(3) corporation, #C2354500, based in San Francisco, California, US 



























"
